---
title: "Guide to DID estimators"
author: 
  - Corinne A. Riddell, University of California, Berkeley
  - Dana E. Goin, University of California, San Francisco
output:
  html_document:
    number_sections: yes
    theme: lumen
    toc: yes
    toc_collapsed: yes
    toc_depth: 3
    toc_float: yes
  pdf_document:
    toc: yes
    toc_depth: '3'
---

```{r, echo = F}
colorize <- function(x, color) {
  if (knitr::is_latex_output()) {
    sprintf("\\textcolor{%s}{%s}", color, x)
  } else if (knitr::is_html_output()) {
    sprintf("<b><span style='color: %s;'>%s</span></b>", color,
      x)
  } else x
}


library(r2symbols)
```

# How to use this website

## Citations

This website was developed by Corinne Riddell and Dana Goin, epidemiologists at 
the University of California, Berkeley (UC Berkeley) and San Francisco (UCSF), 
respectively. If you use this website to inform your research, please use the 
following citations: 

1. Goin DE, Riddell CA (2022). Comparing two-way fixed effects and new estimators for difference-in-differences: A simulation study and empirical example. Submitted to *Epidemiology*. ADD LINK.

2. Riddell CA, Goin DE (2022). Guide for comparing estimators of policy change effects on health [Letter to the Editor]. Accepted at *Epidemiology*. ADD LINK.

On this website we refer to new estimators and tools from the econometric 
literature. If you use any of the new estimators or tools, you will also want to 
cite the following:

* Paper about the Goodman-Bacon Decomposition: Goodman-Bacon A. Difference-in-differences with variation in treatment timing. *J Econom*. 2021;225(2):254-77.

* Paper about the Group-Time ATT Estimator: Callaway B, Sant’Anna PHC. Difference-in-Differences with multiple time periods. *J Econom*. 2020;225(2):200-30.

* Paper about the Cohort ATT Estimator: Sun L, Abraham S. Estimating dynamic treatment effects in event studies with heterogeneous treatment effects. *J Econom*. 2021;225(2):175–99. 

* Paper about the Target Trial Estimator: Ben-Michael E, Feller A, Stuart EA. A Trial Emulation Approach for Policy Evaluations with Group-level Longitudinal Data. *Epidemiology*. 2021 Jul;32(4):533–40. 

## License

Guide to DID estimators `r symbol("copyright")` 2022 by Corinne A Riddell and Dana E Goin is licensed 
under the [Creative Commons Attribution-Non-Commercial-NoDerivatives 4.0
License](https://creativecommons.org/licenses/by-nc-nd/4.0/?ref=chooser-v1).

## Contribute fixes and improvements

This website is under development. If you find an error, or would like to suggest
an improvement, please let us know by opening an issue on [Github](https://github.com/corinne-riddell/Guide-to-DID-estimators)
or submitting a bug report to: c.riddell [AT] berkeley [DOT] edu.

Thank you to [@scottlyden](https://github.com/scottlyden) for contributing a fix
via pull request. 

# Overview

This guide illustrates scenarios in which difference in differences (DID) 
analysis can be applied. We assume readers know what a DID design is, have 
some background knowledge in policy analysis, and have working knowledge of R 
and RStudio. Reviewing the manuscript by Goin and Riddell and its references is 
a great place to start if this guide leaves you with more questions than answers.

We start with the simplest of DID scenarios and slowly amp up the complexity. 
For each scenario we describe a target parameter to estimate and the parameter 
estimated by a two-way fixed effects (TWFE) model. We apply the 
Goodman-Bacon decomposition to this parameter to determine if the TWFE estimate 
is influenced by estimates that are "forbidden" (e.g., ones that compare a 
newly treated state to a previously treated state). The goal is to illustrate 
when the usual TWFE method of estimation provides suitable results and when
the TWFE approach is biased and/or aggregates the individual ATTs in an unintuitive way. In the latter case, we show alternative methods to
estimation to overcome these issues.

In the following examples, the effect of state policy changes on a health 
outcome is the effect of interest. 

## Download data and code

To get a local version of the data and code used for this analysis, you can 
run the following code within RStudio. This will download a local copy of all 
the files contained in the GitHub repository "Guide-to-DID-estimators" on 
Corinne Riddell's GitHub.

```{r, eval = F}
install.packages("usethis") #run this line if you need to install the usethis package
usethis::use_course("corinne-riddell/Guide-to-DID-estimators")
```

By default, this creates a new folder on your desktop. You can specify a 
different directory using the `destdir` argument in the `use_course()` function.

The files will open in RStudio when you run the code. In the future, you can 
open the Guide-to-DID-estimators.Rproj file found in the downloaded folder by 
double clicking it or by using the Select "File" > "Open Project" within RStudio
and choosing the Guide-to-DID-estimators project.

## Load R packages and functions

First, load the packages for reading and plotting the data. The packages `bacondecomp`,  
`did`, and `staggered` are specific to DID analyses. 

```{r load-libraries, warning=F, message=F}
# you will need to install these packages if you don't have them already
# install.packages(c("here", "readxl", "tidyverse", "patchwork", "magrittr", 
# "broom", "ggrepel", "lubridate", "bacondecomp", "staggered", "did"))
# You may also need to download the developer version of `DRDID` before if you
# get an error. To do so use: 
# install.packages("devtools")
# devtools::install_github("pedrohcgs/DRDID")
# Finally, install the package emo from Hadley Wickham's GitHub:
# devtools::install_github("hadley/emo")

library(here) #nice file paths
library(readxl) #read in excel data
library(tidyverse) #collection of packages for data science
library(patchwork) #"stiches" together ggplots
library(magrittr) #pipes
library(broom) #tidy displays
library(ggrepel) #for labelling points on a ggplot
library(lubridate) #helps with date objects
library(bacondecomp) #Goodman Bacon Decomposition
library(did) #Callaway and Sant'Anna estimator for DID
library(staggered) #Sun and Abraham estimator for DID
library(emo) #used to insert emojis into this document
```

One estimator we use in the guide, the Target Trial estimator, was implemented 
using code revised from the creator's [GitHub repository](https://github.com/ebenmichael/policy-trial-emulation). 
We use `source()` to read in the functions below. This code will only work if 
you downloaded the files using the `use_course()` function in the previous step. 

```{r}
source("./helper_func_ed.R")
source("./helper_func_ed_sum.R")
source("./helper_func_ed_sum_hte.R")
source("./helper_func_ed_sum_C.R")
```

The first file is a slightly edited version of the original helper_funcs.R file
found in Eli Ben-Michael's linked GitHub repository. The remaining helper functions 
are ones that Dana Goin made to aggregate the estimates under different settings.

## Package Versions

Since the packages used for these analyses are relatively new, we anticipate 
them to change over time and that these changes may affect the readers ability 
to reproduce the results. For these analyses we used `bacondecomp` version 0.1.1, 
`staggered` version 1.1 and `did` version 2.1.2. If your results differ or you 
get an error running any of the code that uses functions from those packages, 
then it may be because you are using different versions of the packages.

```{r}
packageVersion("bacondecomp")
packageVersion("staggered")
packageVersion("did")
```

# Scenario 1 (2 states by 2 time points)

We first consider the simplest case in which there is one state that never adopts 
the policy (the never-treated group), and one state that does implement the policy 
(the treated group). The groups are observed at two time periods only. 

Below, the data are read in from an Excel spreadsheet. You can open the spreadsheet
in Excel to view it if that comes naturally to you, or, use an R `View()`er window
after you have imported it. The data contain four variables `state`, `time`, 
`policy`, and `outcome`. 

* `state`: ID for the grouping variable
* `time`: Time index, begins at 1
* `policy`: Indicator variable for exposure to the policy change
* `outcome`: The outcome variable

```{r}
s1 <- read_xlsx(here("data", "scenarios.xlsx"), sheet = "scen1",
                col_types = c("text", "text", "text", "numeric"))
# str(s1)
# View(s1)
```
Note that I specified the column types for each variable. I read in the state, 
time, and policy variables as "text" so that R will consider them as 
categorical/factor variables in the analysis (or, using econ-speak, as 
"fixed effects").

## Visualization of Scenario 1

```{r, echo = F}
ggplot(s1, aes(x = time, y = outcome)) + 
  geom_line(aes(group = state, col = state)) +
  geom_point(aes(fill = state, pch = state), size = 4) +
  geom_text(aes(label = outcome), nudge_x = 0.075) +
  scale_fill_manual(values = c("#a6cee3","#005a32")) + 
  scale_color_manual(values = c("#a6cee3","#005a32")) +
  scale_shape_manual(values = c(21, 23)) + 
  theme_bw()
```

The following can be read from the labelled plot:

* Pre-treatment difference of 1
* Post-treatment difference of 3
* Causal effect of policy = 3-1 = 2 
or equivalently, 
* State 1 difference of 5
* State 2 difference of 3
* Causal effect of policy = 5-3 = 2 
under the following assumptions

Three standard assumptions are typical stated in DID papers and required for the 
DID estimate to estimate the causal effect of interest:

1) **Parallel trends** Had the treated group not been treated, the trends for 
the treated state would continue to be the same as the never-treated state during
the post treatment time period. 
2) **No anticipation:** The effect of the policy change begins after it is introduced; 
there is no anticipatory effect before the policy is introduced. Anticipatory
effects occur if individuals change their behavior in anticipation of a 
policy change.
3) **No coincident other changes:** The policy is the only change introduced at 
the specific time it is adopted that causally affects the outcome.

If you're familiar with causal inference theory, you will also know about the main 
assumptions required when estimating causal effects. Ben-Michael et al. list 
these assumptions in [their paper](https://pubmed-ncbi-nlm-nih-gov.libproxy.berkeley.edu/34001754/), and we 
include the assumptions here for reference:

4) **Consistency:** There are no multiple versions of treatment that are unknown
to the investigator. For example, if states introduced a texting ban while 
driving and these bans were associated with different penalties, then the policy
change would not meet the consistency assumption because the different penalties
may have varied effects on the outcome and the investigator is analyzing these 
policies as though they were the same. However, if the investigator knows that 
the penalties differed and estimated the effects accounting for this 
heterogeneity, then the consistency assumption would not be violated.

5) **No interference:** Policies that affect individuals in one state should not 
affect the outcomes of individuals in other states.

6) **Exchangeability:** Had the treated states been untreated, they would have 
experienced the trend in outcomes experienced by the untreated group. This 
causal assumption is the same as the parallel trends assumption. 

7) **Positivity:** Each state has a non-zero probability of being treated. 
According to [Ben-Michael et al](https://pubmed-ncbi-nlm-nih-gov.libproxy.berkeley.edu/34001754/), this assumption is not required for standard DID
models.

8) **Correct model specification**: The parametric model accurately represents
the underlying causal model. 

Lastly, [Athens and Imbens](
https://doi.org/10.1016/j.jeconom.2020.10.012) outline assumptions required for the standard DID 
estimator to be an unbiased estimator of a certain weighted average causal 
effect, including random assignment of the policy's introduction date.

## Two-way fixed effects (TWFE) regression model

Under the canonical TWFE design, we can estimate the policy effect by including
a fixed effect (FE) for state, a FE for time, and an indicator for the policy
change. The indicator should be 1 for when the treated states are in the 
post-treatment period, and 0 otherwise. The effect estimate is the regression 
coefficient on the policy variable.

```{r}
s1_mod <- lm(outcome ~ state + time + policy, data = s1)
tidy(s1_mod)
```

The coefficient on the policy term is `r s1_mod$coefficients[4]` showing that
the regression model estimate equalled the causal effect.

**Note:** that in this scenario and the other simple scenarios we cover, there is no
variability in the data, so the model cannot estimate a standard error (as 
indicated by the `NaN` in the regression output). In a later scenario, we add
noise to the data and show how to estimate the standard error.

## Summary

When there are only two treatment groups and two time points, 
where one of the groups becomes treated, you can calculate the DID estimate 
by hand or using TWFE regression.

# Scenario 2A and 2B (3 states, homogeneous and heterogeneous treatment effects)

This scenario is similar to Scenario 1, except now there are two states that
undergo treatment. In Scenario 2a, the magnitude of the treatment effect is the 
same in both states. In Scenario 2b, the magnitude of the treatment effect 
varies by state.

```{r import-scen2}
s2a <- read_xlsx(here("data", "scenarios.xlsx"), sheet = "scen2a",  
                 col_types = c("text", "text", "text", "numeric"))

s2b <- read_xlsx(here("data", "scenarios.xlsx"), sheet = "scen2b",
                  col_types = c("text", "text", "text", "numeric"))

s2a %<>% mutate(ever_trt = case_when(state %in% c("2", "3") ~ "treated",
                                     state == "1" ~ "never-treated"))

s2b %<>% mutate(ever_trt = case_when(state %in% c("2", "3") ~ "treated",
                                     state == "1" ~ "never-treated"))
```

## Visualization of Scenario 2

```{r, echo=F}
s2a_plot <-ggplot(s2a, aes(x = time, y = outcome)) + 
  geom_line(aes(group = state, col = state)) +
  geom_point(aes(fill = state, pch = ever_trt), size = 4) +
  geom_text(aes(label = outcome), nudge_x = 0.1) +
  scale_fill_manual(values = c("#a6cee3","#005a32", "#99000d"), guide = "none") +
  scale_color_manual(values = c("#a6cee3","#005a32", "#99000d")) +
  scale_shape_manual(values = c(21, 23)) + 
  theme_bw() + labs(title = "Scenario 2a")

s2b_plot <-ggplot(s2b, aes(x = time, y = outcome)) + 
  geom_line(aes(group = state, col = state)) +
  geom_point(aes(fill = state, pch = ever_trt), size = 4) +
  geom_text(aes(label = outcome), nudge_x = 0.1) +
  scale_fill_manual(values = c("#a6cee3","#005a32", "#99000d"), guide = "none") +
  scale_color_manual(values = c("#a6cee3","#005a32", "#99000d")) +
  scale_shape_manual(values = c(21, 23)) + 
  theme_bw() + labs(title = "Scenario 2b")

s2a_plot + s2b_plot + plot_layout(guides = "collect")  & 
  scale_y_continuous(limits = range(c(s2a$outcome, s2b$outcome)))
```

The following can be read from the labelled plot for Scenario 2a:

* Post-Pre Difference for never-treated state 1: 12-9=3
* Post-Pre Difference for treated state 2: 15-10=5
* Post-Pre Difference for treated state 3: 16-11=5
* Causal effect of policy = 5-3 for both states for an average treatment effect on the treated (ATT) of 2

The following can be read from the labelled plot for Scenario 2b:

* Post-Pre Difference for never-treated state 1: 12-9=3
* Post-Pre Difference for treated state 2: 15-10=5
* Post-Pre Difference for treated state 3: 17-11=6
* Causal effect of policy = 2 for state 2 vs 1 and 3 for state 3 vs 1 for an ATT of 2.5

## TWFE Regression model

```{r}
s2a_mod <- lm(outcome ~ policy + state + time, data = s2a)
tidy(s2a_mod)
```

The coefficient estimate for the policy variable equals to 
`r s2a_mod$coefficients["policy1"]`, which is the ATT for Scenario 2a. 

```{r}
s2b_mod <- lm(outcome ~ policy + state + time, data = s2b)
tidy(s2b_mod)
```

The coefficient estimate for the policy variable equals to 
`r s2b_mod$coefficients["policy1"]`, which is the ATT for Scenario 2b. 

## Summary

When there are multiple treatment groups and two time points, 
where >1 of the groups becomes treated, you can calculate the DID estimate by 
hand or using TWFE regression. If treatment effects are heterogeneous across 
states, then the estimated effect is the average ATT across the 
states.

# Scenario 3A and 3B (Two states, multiple time points)

In Scenario 3, the number of time periods is increased to incorporate 5 time 
points before and after a policy change. One never-treated and one treated
group are considered. In Scenario 3a, the effect of treatment is constant once
treatment is introduced. In Scenario 3b, the effect of treatment increases with 
time (i.e., it is dynamic).

Because there are multiple time points, when we read in the data we update the 
column type for the time variable to be numeric. This will help with plotting 
the data. 

```{r}
s3a <- read_xlsx(here("data", "scenarios.xlsx"), sheet = "scen3a",
                 col_types = c("text", "numeric", "text", "numeric", "text"))

s3b <- read_xlsx(here("data", "scenarios.xlsx"), sheet = "scen3b",
                 col_types = c("text", "numeric", "text", "numeric", "text"))
```

In addition to `state`, `time`, `policy`, and `outcome`, the data contains 
another variable `time_since_policy` which equals 0 before treatment (and 
always equals 0 for the never-treated), and counts the time since treatment in
the treated state.

```{r, echo = F, warning = F}

# Because there are multiple time points, we first take the average of the outcome
# during the pre and post-treatment time period separately for each state. 

#first, add an indicator indicating time post treatment.
s3a %<>% mutate(post = time >= 6) 
s3b %<>% mutate(post = time >= 6)

s3a_mean_info <- s3a %>% 
  group_by(state, post) %>%
  summarise(mean_y = mean(outcome), .groups = 'drop') %>% 
  pivot_wider(id_cols = state, 
              names_from = post, 
              names_pre = "post_",
              values_from = mean_y) %>%
  mutate(diff = post_TRUE - post_FALSE)

s3b_mean_info <- s3b %>% group_by(state, post) %>%
  summarise(mean_y = mean(outcome), .groups = 'drop') %>% 
  pivot_wider(id_cols = state,
              names_from = post,
              names_pre = "post_",
              values_from = mean_y) %>%
  mutate(diff = post_TRUE - post_FALSE)
```

## Visualization of Scenario 3

```{r, echo=F, fig.height = 5, fig.width = 10}
s3a %<>% mutate(ever_trt = case_when(state == "2" ~ "treated",
                                     state == "1" ~ "never-treated"))

s3b %<>% mutate(ever_trt = case_when(state == "2" ~ "treated",
                                     state == "1" ~ "never-treated"))

s3a_plot <- ggplot(s3a, aes(x = time, y = outcome)) + 
  geom_line(aes(col = state)) + 
  geom_point(aes(fill = state, pch = ever_trt)) +
  labs(title = "Scenario 3a (Constant change)") +
  geom_vline(aes(xintercept = 5.5), lty = 2) + 
  geom_label(data = s3a_mean_info, 
            aes(y = post_FALSE, x = 4, 
                col = state, 
                label = paste("y_mean= ", post_FALSE)),
            nudge_y = 0.1,
            show.legend = FALSE) +
    geom_label(data = s3a_mean_info, 
            aes(y = post_TRUE, x = 8, 
                col = state, 
                label = paste("y_mean= ", post_TRUE)),
            nudge_y = 0.1,
            show.legend = FALSE) +
  scale_fill_manual(values = c("#a6cee3","#005a32"), guide = "none") +
  scale_color_manual(values = c("#a6cee3","#005a32")) +
  scale_shape_manual(values = c(21, 23)) + 
  theme_bw()

s3b_plot <- ggplot(s3b, aes(x = time, y = outcome)) + 
  geom_line(aes(col = state)) + 
  geom_point(aes(fill = state, pch = ever_trt)) + 
  labs(title = "Scenario 3b (Dynamic change)") +
  geom_vline(aes(xintercept = 5.5), lty = 2) + 
  geom_label(data = s3b_mean_info, 
            aes(y = post_FALSE, x = 4, 
                col = state, 
                label = paste("y_mean= ", post_FALSE)),
            nudge_y = 0.1,
            show.legend = FALSE) +
    geom_label(data = s3b_mean_info, 
            aes(y = post_TRUE, x = 8, 
                col = state, 
                label = paste("y_mean= ", post_TRUE)),
            nudge_y = 0.1,
            show.legend = FALSE) +
  scale_fill_manual(values = c("#a6cee3","#005a32"), guide = "none") +
  scale_color_manual(values = c("#a6cee3","#005a32")) +
  scale_shape_manual(values = c(21, 23)) + 
  theme_bw()

s3a_plot + s3b_plot + plot_layout(guides = "collect")  & 
  scale_y_continuous(limits = range(c(s3a$outcome, s3b$outcome)))
```

The following can be read from the labelled plot for Scenario 3a:

* Pre-treatment difference is 17-15=2
* Post-treatment difference is 34-30=4
* DID = 2

The following can be read from the labelled plot for Scenario 3b:

* Pre-treatment difference is 17-15=2
* Post-treatment difference is 38-30=8
* DID = 6

For Scenario 3b the effect is dynamic, and rather than 
calculating an ATT that aggregates over post-time, we may want to calculate 
the effect separately by time since treatment. Here, the effect increases over 
time. This could happen if the policy change takes time to "kick-in" (so it
might level off after more time passes) or if there is a positive feedback loop. 

In contrast,  some policies may be associated with large initial effects that attenuate over 
time. Knowing if a policy introduction is associated with a changing effect over
time is therefore important for understanding the real-world effects of the policy. 

Thus, in this scenario we first estimate the average treatment effect using a 
TWFE model, and then we estimate the dynamic effect by extending the TWFE model
to include a categorical indicator for time since the policy's introduction. 

## TWFE Regression Model

Estimation of the dynamic effect in Scenario 3a. Different from the previous 
scenarios, we need to use `factor(time)` to ensure time is modeled using 
indicator variables (i.e., time fixed effects) since we imported it as a numeric
variable in this scenario to make plotting easier. 

```{r}
s3a_mod <- lm(outcome ~ policy + state + factor(time), 
             data = s3a)
tidy(s3a_mod)
```

The coefficient of the policy term for scenario 3a is `r s3a_mod$coefficients["policy1"]`
showing that the regression model estimate equaled the causal effect.

Estimation of the dynamic effect in Scenario 3b:

```{r}
s3b_mod <- lm(outcome ~ policy + state + factor(time), 
             data = s3b)
tidy(s3b_mod)
```

The coefficient of the policy term for scenario 3b is `r s3b_mod$coefficients["policy1"]`
showing that the regression model estimate equaled the causal effect.

## TWFE Regression Model with `time_since_policy` specification

Rather than using a binary indicator for the policy change, it can be coded
using the `time_since_policy` variable. If we include this as a factor variable
in the model, then separate effects will be estimated for each time since 
treatment. 

For Scenario 3a, using this variable should yield 2 for each time since treatment,
since the treatment effect is constant over time.

```{r}
s3a_mod2 <- lm(outcome ~ time_since_policy + state + factor(time), 
             data = s3a)
tidy(s3a_mod2)
```

Indeed, this is what we see.

For Scenario 3b, the effect increases by 2 units for every unit of time since
treatment is initiated so this should be reflected in the coefficient estimates.

```{r}
s3b_mod2 <- lm(outcome ~ time_since_policy + state + factor(time), 
             data = s3b)
tidy(s3b_mod2)
```

For this scenario, the effect estimate is 2 in the first time after treatment, 
then 4, and so on. 

Note that we could have modeled `time_since_policy` linearly (e.g., by including
a numeric variable for `time_since_policy`). Here, we modeled `time_since_policy`
as a factor variable, which allows the effect estimates to change non-linearly 
over time.

## Summary

When there is one treated group and one control group, with 
multiple pre- and post- time points, you can calculate the DID estimate using 
TWFE regression when the effect is constant or dynamic. Using a "time since 
treatment" indicator will estimate effects separately by time since the policy 
change, allowing you to see how the effect has changed over time.

# Scenario 4 (4 states, heterogeneous treatment effects)

Scenario 4 extends Scenario 3 to the multiple group setting. State 1 is 
never-treated, while states 2-4 undergo treatment at time=6. The effects are 
not dynamic in time, but they are heterogeneous with some states having a larger
treatment effect. 

Note there are two new columns `time_as_date` and `time_first_trt_date` that we
will use later in this example.

```{r}
s4 <- read_xlsx(here("data", "scenarios.xlsx"), sheet = "scen4",
                col_types = c("text", "numeric", "text", "numeric", "text", "numeric", "date", "date"))
```

```{r, echo=F}
s4 %<>% mutate(post = time >= 6)

s4 %<>% mutate(ever_trt = case_when(state %in% c("2", "3", "4") ~ "treated",
                                     state == "1" ~ "never-treated"))

s4_mean_info <- s4 %>% group_by(state, post) %>%
  summarise(mean_y = mean(outcome), .groups = "drop") %>% 
  pivot_wider(id_cols = state, names_from = post, names_pre = "post_", values_from = mean_y) %>%
  mutate(diff = post_TRUE - post_FALSE)
```

## Visualization of Scenario 4

```{r, echo=F}
ggplot(s4, aes(x = time, y = outcome)) + 
  geom_line(aes(col = state)) + 
  geom_point(aes(fill = state, pch = ever_trt)) + labs(title = "Scenario 4") +
  geom_vline(aes(xintercept = 5.5), lty = 2) + 
  geom_label(data = s4_mean_info, 
            aes(y = post_FALSE, x = 4, 
                col = state, 
                label = paste("y_mean= ", post_FALSE)),
            show.legend = FALSE) +
    geom_label(data = s4_mean_info, 
            aes(y = post_TRUE, x = 8, 
                col = state, 
                label = paste("y_mean= ", post_TRUE)),
            show.legend = FALSE) + 
  theme_bw() +
  scale_color_manual(values = c("#a6cee3","#1f78b4","#005a32", "#99000d")) + 
  scale_fill_manual(values = c("#a6cee3","#1f78b4","#005a32", "#99000d")) + 
  scale_shape_manual(values = c(21, 23, 23, 23))
```

The following can be read from the labelled plot:

* Pre-post difference for never-treated state 1: 30-15 = 15
* Pre-post difference for treated state 2: 34-17 = 17
* Pre-post difference for treated state 3: 35-19 = 16
* Pre-post difference for treated state 4: 39-21 = 18

* $DID_{2 vs 1} = 17-15 = 2$
* $DID_{3 vs 1} = 16-15 = 1$
* $DID_{4 vs 1} = 18-15 = 3$
* $\text{Average ATT} = (2 + 1 + 3)/3 = 2$

## TWFE Regression Model 

```{r}
s4_mod <- lm(outcome ~ policy + state + factor(time), 
             data = s4)
tidy(s4_mod)
```

The coefficient of the policy term is `r s4_mod$coefficients["policy1"]`
showing that the regression model estimates the ATT.

In this scenario and the ones considered before it we have not needed to use the 
new estimators because the TWFE uncover the true effect -- this is the case 
because the policy change was introduced at one time point in each scenario. 
Below, we show how to use the Goodman-Bacon decomposition function `bacon()`, 
to show how its results in the case where the standard DID approach works so that 
you can contrast this with later scenarios where the standard approach fails.

## Goodman Bacon Decomposition 

Before using the `bacon()` function, we need to create numeric-coded versions of
some of the variables that are stored as characters: 

```{r}
s4 %<>% mutate(state_n = as.numeric(as.character(state)),
               policy_n = as.numeric(as.character(policy)))
```

The `bacon` function has an argument called `formula`, where you list the outcome
as a function of the policy change, i.e., `formula = outcome ~ policy_n`. Note 
that no fixed effects for state or time are included in the formula. Instead, 
the time and state fixedeffects are specified by the `time_var`and `id_var` 
arguments.

```{r}
s4_bacon <- bacon(formula = outcome ~ policy_n, 
                  data = s4,
                  id_var = "state_n",
                  time_var = "time")
```

This small table illustrates that 100% of the weight is put on comparisons between
treated and untreated states and the ATT equals 2.

For more detail we  print the object:

```{r}
s4_bacon 
```

`treated=6` says that all treated states start treatment at time = 6 and are
compared to untreated states (with a fictitious treatment time of 99999).

The results from the Goodman-Bacon Decomposition are reassuring and tell us we
can trust the TWFE estimate. For pedagodgical purposes, we also calculate the 
Group-Time ATT estimator using the `att_gt` function.

## Group-Time ATT Estimator

Like `bacon()`, `att_gt()` requires all numeric variables. It also requires an
argument called `gname`. `gname` expects a variable which encodes for each state
the time of first policy change. For never-treated state 1, this variable 
equals 0 and for treated states 2-4 this variable equals 6. Another important
argument in the function is `control_group` which you can set to "nevertreated"
or "notyettreated". When specifying "control_group=nevertreated", only states 
that never receive the policy change are used as control states. When specifying "control_group=notyettreated", the control group expands to include states that
have not yet received treatment at the time of the policy's introduction. In
this guide, we use "notyetreated" as the control group since these states satisfy
the parallel trends assumption and including them would increase statistical 
precision (if there were noise in the estimates).

```{r, warning=F}
s4_cs <- att_gt(yname = "outcome", 
             tname = "time", 
             idname = "state_n", 
             gname = "time_first_treat", 
             data = s4, 
             control_group = "notyettreated",
             anticipation = 0)

m2_ag <- aggte(s4_cs, type="simple")
summary(m2_ag)
```

Here, we see the ATT is equal to `r m2_ag$overall.att` as estimated by the TWFE 
model.

## Target Trial Estimator

We can also calculate the estimate using the Target Trial Estimator introduced 
by Ben-Michael, Feller, and Stuart. We employ slightly edited versions of the 
code that these authors provide with their published article. The code 
calculates estimates of the effect for every event time (also called time since 
treatment). We built upon this code to further aggregate across event times to 
produce one overall estimate using `fit_event_jack_sum()`, 
`fit_event_jack_sum_hte()`, and `fit_event_jack_sum_C()` functions. Use 
`fit_event_jack_sum()` when there is only one adoption cohort, as shown here.

Note that when you run this function, messages are printed to the screen of the
form "Dropping #". These messages are outputted by the jackknife function that
drops one unit at a time when estimating the standard error. You will see them
printed below and each time we use one of `the fit_event_jack*()` functions.

```{r}
s4_bm <- fit_event_jack_sum(outcome_var = "outcome", 
                            date_var = "time_as_date", 
                            unit_var = "state",
                            policy_var = "time_first_trt_date", 
                            data = s4, 
                            max_time_to = 10000)

s4_bm %<>% mutate(lb = estimate - 1.96*se,
                      ub = estimate + 1.96*se)

s4_bm
```

The ATT is equal to the effect estimated by the TWFE and Group-Time estimators.

Ideally, we would also show you how to run the Cohort ATT estimator for 
this scenario but the function to do so, `staggered_sa()`, throws an error 
when trying to estimate the standard error. Thus, we will show you how to use
this function in the scenario that incorporates noise into the data.

# Scenario 5 (4 states, staggered treatment timing)

Scenario 5 introduces staggered timing. In this example, the treated states 
introduce the policy at two different time points. The treatment effects are 
neither heterogeneous or dynamic. There are two never-treated states and two 
ever-treated states.

```{r}
s5 <- read_xlsx(here("data", "scenarios.xlsx"), sheet = "scen5",
                col_types = c("text", "numeric", "text", "numeric", "text", "numeric", 
                              "date", "date"))
```

## Visualization of Scenario 5

```{r, echo = F}

s5 %<>% mutate(ever_trt = case_when(state %in% c("3", "4") ~ "treated",
                                     state %in% c("1", "2") ~ "never-treated"))

ggplot(s5, aes(x = time, y = outcome)) + 
  geom_line(aes(col = state)) + 
  geom_point(aes(fill = state, pch = ever_trt)) + labs(title = "Scenario 5 (Staggered timing)") +
  geom_vline(aes(xintercept = 4.5), lty = 2, col = "#005a32") + 
  geom_vline(aes(xintercept = 11.5), lty = 2, col = "#99000d") +
  scale_fill_manual(values = c("#a6cee3","#1f78b4","#005a32", "#99000d")) +
  scale_color_manual(values = c("#a6cee3","#1f78b4","#005a32", "#99000d")) +
  scale_shape_manual(values = c(21, 23)) + 
  theme_bw()
```

**Visualization of all comparisons made by TWFE regression**

```{r, echo = F}
mean_1_4 <- s5 %>% filter(time < 5) %>%
  group_by(state) %>%
  summarise(mean_1_4 = mean(outcome))

mean_5_20 <- s5 %>% filter(time >= 5) %>%
  group_by(state) %>%
  summarise(mean_5_20 = mean(outcome))

DID1 <- bind_cols(mean_1_4, 
                  mean_5_20 %>% select(-state)) %>%
  mutate(time_diff1 = mean_5_20 - mean_1_4)

mean_1_11 <- s5 %>% filter(time < 12) %>%
  group_by(state) %>%
  summarise(mean_1_11 = mean(outcome))

mean_12_20 <- s5 %>% filter(time >= 12) %>%
  group_by(state) %>%
  summarise(mean_12_20 = mean(outcome))

DID2 <- bind_cols(mean_1_11, 
                  mean_12_20 %>% select(-state)) %>%
  mutate(time_diff2 = mean_12_20 - mean_1_11)

mean_5_11 <- s5 %>% filter(time >= 5 & time < 12) %>%
  group_by(state) %>%
  summarise(mean_5_11 = mean(outcome))

DID3 <- bind_cols(mean_1_4, 
                  mean_5_11 %>% select(-state)) %>%
  mutate(time_diff3 = mean_5_11 - mean_1_4)

DID4 <- bind_cols(mean_5_11, 
                  mean_12_20 %>% select(-state)) %>%
  mutate(time_diff4 = mean_12_20 - mean_5_11)
```

```{r, echo = F, fig.height = 8, fig.width = 10}
s5_comp1 <- ggplot(s5 %>% filter(state %in% c(1, 2, 3)), aes(x = time, y = outcome)) +   
  geom_line(aes(col = factor(state))) + 
  geom_point(aes(fill = factor(state), pch = ever_trt), show.legend = F) + labs(title = "A) Contrast 1 (Earlier treated vs. untreated)") +
  geom_vline(aes(xintercept = 4.5), lty = 2)  +
  geom_label_repel(data = DID1 %>% filter(state %in% c(1,2,3)), 
                  aes(y = mean_1_4, x = 2.5, label = paste("mean_y:", mean_1_4), col = state), show.legend = F) +
  geom_label_repel(data = DID1 %>% filter(state %in% c(1,2,3)), 
                  aes(y = mean_5_20, x = 12.5, label = paste("mean_y:", mean_5_20), col = state), show.legend = F) +
  theme_bw() + 
  scale_x_continuous(limits = c(1, 20)) + 
  scale_shape_manual(values = c(21, 23)) + 
  scale_fill_manual(values = c("#a6cee3","#1f78b4","#005a32")) +
  scale_color_manual(values = c("#a6cee3","#1f78b4","#005a32"))

s5_comp2 <- ggplot(s5 %>% filter(state %in% c(1, 2, 4)), aes(x = time, y = outcome)) +   
  geom_line(aes(col = factor(state))) + 
  geom_point(aes(fill = factor(state), pch = ever_trt), show.legend = F) + labs(title = "B) Contrast 2 (Later treated vs. untreated)") +
  geom_vline(aes(xintercept = 11.5), lty = 2) +
  geom_label_repel(data = DID2 %>% filter(state %in% c(1,2,4)), 
                   aes(y = mean_1_11, x = 6, label = paste("mean_y:", mean_1_11), col = state), show.legend = F) +
  geom_label_repel(data = DID2 %>% filter(state %in% c(1,2,4)), 
                   aes(y = mean_12_20, x = 16, label = paste("mean_y:", mean_12_20), col = state), show.legend = F) +
  theme_bw() + 
  scale_x_continuous(limits = c(1, 20)) + 
  scale_shape_manual(values = c(21, 23)) + 
  scale_fill_manual(values = c("#a6cee3","#1f78b4","#99000d")) +
  scale_color_manual(values = c("#a6cee3","#1f78b4","#99000d"))

s5_comp4 <- ggplot(s5 %>% filter(state %in% c(3, 4), time >= 5), aes(x = time, y = outcome)) +   
  geom_line(aes(col = factor(state))) +
  geom_point(aes(fill = factor(state), pch = ever_trt), show.legend = F) + labs(title = "C) Contrast 4 (Earlier vs. later treated)") +
  geom_vline(aes(xintercept = 11.5), lty = 2) +
  geom_label_repel(data = DID4 %>% filter(state %in% c(3,4)), 
                   aes(y = mean_5_11, x = 8, label = paste("mean_y:", mean_5_11), col = state), show.legend = F) +
  geom_label_repel(data = DID4 %>% filter(state %in% c(3,4)), 
                   aes(y = mean_12_20, x = 16, label = paste("mean_y:", mean_12_20), col = state), show.legend = F) +
  theme_bw() + 
  scale_x_continuous(limits = c(1, 20)) + 
  scale_shape_manual(values = 23) + 
  scale_fill_manual(values = c("#005a32", "#99000d")) +
  scale_color_manual(values = c("#005a32", "#99000d"))

s5_comp3 <- ggplot(s5 %>% filter(state %in% c(3, 4), time < 12), aes(x = time, y = outcome)) +   
  geom_line(aes(col = factor(state))) + 
  geom_point(aes(fill = factor(state), pch = ever_trt), show.legend = F) + labs(title = "D) Contrast 3 (Later vs. earlier treated)") +
  geom_vline(aes(xintercept = 4.5), lty = 2) +
  geom_label_repel(data = DID3 %>% filter(state %in% c(3,4)), 
                   aes(y = mean_1_4, x = 2.5, label = paste("mean_y:", mean_1_4), col = state), show.legend = F) +
  geom_label_repel(data = DID3 %>% filter(state %in% c(3,4)), 
                   aes(y = mean_5_11, x = 8, label = paste("mean_y:", mean_5_11), col = state), show.legend = F) +
  theme_bw() + 
  scale_x_continuous(limits = c(1, 20)) + 
  scale_shape_manual(values = 23) + 
  scale_fill_manual(values = c("#005a32", "#99000d")) +
  scale_color_manual(values = c("#005a32", "#99000d"))

s5_comp1 + s5_comp2 + s5_comp3 + s5_comp4 + plot_layout(guides = "collect")
```

**Contrast 1:**

* Pre-post difference for never-treated state 1 is: 43.5-13.5=30
* Pre-post difference for never-treated state 2 is: 44.5-14.5=30
* Implying the average pre-post difference equals 30 for the never-treated states
* Pre-post difference for treated state 3 is 49.5-16.5 = 33
* $DID_{3 vs 1,2} = 33-30=3$

**Contrast 2:**

* Pre-post difference for never-treated state 1 is: 54-24=30
* Pre-post difference for never-treated state 2 is: 55-25=30
* Implying the average pre-post difference equals 30 for the never-treated states
* Pre-post difference for treated state 4 is 66-33= 33
* $DID_{4 vs 1,2} = 33-30=3$

**Contrast 3:**

* Pre-post difference for later-treated state 4 is: 39-22.5=16.5
* Pre-post difference for earlier-treated state 2 is: 36-16.5=19.5
* $DID_{3 vs 4} = 19.5-16.5=3$

**Contrast 4:**

* Pre-post difference for earlier-treated state 2 is: 60-36=24
* Pre-post difference for later-treated state 4 is: 66-39=27
* $DID_{4 vs 3} = 27-24=3$

Since the causal effect equals 3 across all contrasts, and all contrasts are 
valid, this is the quantity that we want the TWFE and new estimators to estimate.


## TWFE Regression Model

```{r}
s5_mod <- lm(outcome ~  policy + state + factor(time), data = s5)
tidy(s5_mod)
```

The coefficient of the policy term is `r s5_mod$coefficients["policy1"]`
showing that the regression model estimates the ATT.

## Goodman Bacon Decomposition

Using the `bacon()`function, we can see see the four comparisons being made and
the effect estimates for each comparison. The weight column in the output shows
how much weight each estimate contributes to the ATT. Here, the treated vs 
untreated comparisons are the most heavily weighted. 

```{r}
s5 %<>% mutate(state_n = as.numeric(as.character(state)),
               policy_n = as.numeric(as.character(policy)))
#bacon decomp says no problems
#only comparing treated vs untreated and the average effect estimate is 2
s5_bacon <- bacon(outcome ~ policy_n,
      data = s5,
      id_var = "state_n",
      time_var = "time")
```

We can also see a list of each comparison and its weight: 

```{r}
s5_bacon
```

## Group-Time ATT Estimator

For pedagogical purposes, we also show the estimate if we applied the Callaway 
Sant’Anna estimator using the `att_gt()` function to estimate group-time ATTs.

```{r, warning=FALSE}
s5_cs <- att_gt(yname = "outcome", 
             tname = "time", 
             idname = "state_n", 
             gname = "time_first_treat", 
             data = s5, 
             control_group = "notyettreated",
             anticipation = 0)
```

Note that I suppressed the warnings by using `warning=FALSE` in the R markdown
chunk header for this specific chunk. This is because it prints more than 100
lines of the same warning "## Warning in max(abs(b/bSigma), na.rm = TRUE): no non-missing arguments to max;
## returning -Inf". This warning is because there is no variability in the the 
data so the model cannot estimate a standard error. This is not realistic, and in
a later example we incorporate variability. I suppress the warnings in this
document whenever they are too numerous. In practice, you will want to 
heed warnings and understand why they occur before suppressing them.

```{r}
s5_cs_ag <- aggte(s5_cs, type="simple")
summary(s5_cs_ag)
```

Here, we see the ATT is equal to `r s5_cs_ag$overall.att` as estimated by the 
TWFE model.

## Target Trial Estimator

We can also calculate the estimate using the Target Trial Estimator. Here we use
`fit_event_jack_sum()` because the effect is not heterogeneous.

```{r}
s5_bm <- fit_event_jack_sum(outcome_var = "outcome", 
                            date_var = "time_as_date", 
                            unit_var = "state",
                            policy_var = "time_first_trt_date", 
                            data = s5, 
                            max_time_to = 10000)

s5_bm %<>% mutate(lb = estimate - 1.96*se,
                      ub = estimate + 1.96*se)

s5_bm
```

This method also estimates an effect of 3, the true estimate, and the same as 
the other estimators.

## Summary

When a policy's introduction is staggered in time and the treatment
effect is constant (not dynamic or heterogeneous), TWFE can be used to estimate
the treatment effect.

# Scenario 6 (4 states, staggered timing, dynamic effects)

Scenario 6 is similar to Scenario 5 except now the treatment effect increases
as time goes on, i.e., it is dynamic. The magnitude of the treatment effect is
the same for both treated groups.

```{r}
# here we also specify the range of the data to be read into R because we don't
# want to include other information included in this sheet
s6 <- read_xlsx(here("data", "scenarios.xlsx"), sheet = "scen6", range = "A1:H81",
                col_types = c("text", "numeric", "text", "numeric", "text", "numeric",
                              "date", "date"))
```

## Visualization of Scenario 6

```{r, echo=F}
s6 %<>% mutate(ever_trt = case_when(state %in% c(3, 4) ~ "treated", 
                                    state %in% c(1, 2) ~ "untreated"))
ggplot(s6, aes(x = time, y = outcome)) + 
  geom_line(aes(col = factor(state))) + 
  geom_point(aes(fill = factor(state), pch = ever_trt)) + 
  labs(title = "Scenario 6 (Dynamic)") +
  geom_vline(aes(xintercept = 4.5), lty = 2, col = "#005a32") + 
  geom_vline(aes(xintercept = 11.5), lty = 2, col = "#99000d") +
  scale_fill_manual(values = c("#a6cee3","#1f78b4","#005a32", "#99000d")) +
  scale_color_manual(values = c("#a6cee3","#1f78b4","#005a32", "#99000d")) +
  scale_shape_manual(values = c(23, 21)) + 
  theme_bw()

```

**Visualization of all comparisons made by TWFE regression**

```{r, echo=F}
s6_mean_1_4 <- s6 %>% filter(time < 5) %>%
  group_by(state) %>%
  summarise(mean_1_4 = mean(outcome))

s6_mean_5_20 <- s6 %>% filter(time >= 5) %>%
  group_by(state) %>%
  summarise(mean_5_20 = mean(outcome))

s6_DID1 <- bind_cols(s6_mean_1_4, s6_mean_5_20 %>% select(-state)) %>%
  mutate(time_diff = mean_5_20 - mean_1_4)


s6_mean_1_11 <- s6 %>% filter(time < 12) %>%
  group_by(state) %>%
  summarise(mean_1_11 = mean(outcome))

s6_mean_12_20 <- s6 %>% filter(time >= 12) %>%
  group_by(state) %>%
  summarise(mean_12_20 = mean(outcome))

s6_DID2 <- bind_cols(s6_mean_1_11, 
                     s6_mean_12_20 %>% select(-state)) %>%
  mutate(time_diff2 = mean_12_20 - mean_1_11)

s6_mean_5_11 <- s6 %>% filter(time >= 5 & time < 12) %>%
  group_by(state) %>%
  summarise(mean_5_11 = mean(outcome))

s6_DID3 <- bind_cols(s6_mean_1_4, 
                     s6_mean_5_11 %>% select(-state)) %>%
  mutate(time_diff3 = mean_5_11 - mean_1_4)

s6_DID4 <- bind_cols(s6_mean_5_11, 
                     s6_mean_12_20 %>% select(-state)) %>%
  mutate(time_diff4 = mean_12_20 - mean_5_11)
```

```{r, echo = F, fig.height = 8, fig.width = 10}
s6_comp1 <- ggplot(s6 %>% filter(state %in% c(1, 2, 3)), aes(x = time, y = outcome)) + 
  geom_line(aes(col = factor(state))) + 
  geom_point(aes(fill = factor(state), pch = ever_trt)) + labs(title = "A) Contrast 1 (Treated vs. never-treated)") +
  geom_vline(aes(xintercept = 4.5), lty = 2) +
  scale_color_manual(values = c("#a6cee3","#1f78b4","#005a32")) +
  scale_fill_manual(values = c("#a6cee3","#1f78b4","#005a32")) +
  theme_bw() + 
  scale_x_continuous(limits = c(1, 20)) +
  scale_shape_manual(values = c(23, 21)) + 
  geom_label_repel(data = s6_DID1 %>% filter(state %in% c(1,2,3)), 
                  aes(y = mean_1_4, x = 2.5, label = paste("mean_y:", mean_1_4), col = state), show.legend = F) +
  geom_label_repel(data = s6_DID1 %>% filter(state %in% c(1,2,3)), 
                  aes(y = mean_5_20, x = 12.5, label = paste("mean_y:", mean_5_20), col = state), show.legend = F)
 
s6_comp2 <- ggplot(s6 %>% filter(state %in% c(1, 2, 4)), aes(x = time, y = outcome)) + 
  geom_line(aes(col = factor(state))) +
  geom_point(aes(fill = factor(state),  pch = ever_trt)) + labs(title = "B) Contrast 2 (Treated vs. never-treated)") +
  geom_vline(aes(xintercept = 11.5), lty = 2) +
  scale_color_manual(values = c("#a6cee3","#1f78b4","#99000d")) +
  scale_fill_manual(values = c("#a6cee3","#1f78b4","#99000d")) +
  theme_bw()+ 
  scale_x_continuous(limits = c(1, 20)) +
  scale_shape_manual(values = c(23, 21)) + 
  geom_label_repel(data = s6_DID2 %>% filter(state %in% c(1,2,4)), 
                   aes(y = mean_1_11, x = 6, label = paste("mean_y:", mean_1_11), col = state), show.legend = F) +
  geom_label_repel(data = s6_DID2 %>% filter(state %in% c(1,2,4)), 
                   aes(y = mean_12_20, x = 16, label = paste("mean_y:", mean_12_20), col = state), show.legend = F)

s6_comp4 <- ggplot(s6 %>% filter(state %in% c(3, 4), time >= 5), aes(x = time, y = outcome)) +  
  geom_line(aes(col = factor(state))) + 
  geom_point(aes(fill = factor(state), pch = ever_trt)) + labs(title = "C) Contrast 4 (Later vs. earlier-treated)") +
  geom_vline(aes(xintercept = 11.5), lty = 2) +
  scale_color_manual(values = c("#005a32", "#99000d")) +
  scale_fill_manual(values = c("#005a32", "#99000d")) +
  scale_shape_manual(values = c(23)) + 
  theme_bw()+ 
  scale_x_continuous(limits = c(1, 20)) +
  geom_label_repel(data = s6_DID4 %>% filter(state %in% c(3,4)), 
                   aes(y = mean_5_11, x = 8, label = paste("mean_y:", mean_5_11), col = state), show.legend = F) +
  geom_label_repel(data = s6_DID4 %>% filter(state %in% c(3,4)), 
                   aes(y = mean_12_20, x = 16, label = paste("mean_y:", mean_12_20), col = state), show.legend = F)

s6_comp3 <- ggplot(s6 %>% filter(state %in% c(3, 4), time < 12), aes(x = time, y = outcome)) +   
  geom_line(aes(col = factor(state))) + 
  geom_point(aes(fill = factor(state), pch = ever_trt)) + labs(title = "D) Contrast 3 (Earlier vs. later-treated)") +
  geom_vline(aes(xintercept = 4.5), lty = 2) +
  scale_color_manual(values = c("#005a32", "#99000d")) +
  scale_fill_manual(values = c("#005a32", "#99000d")) +
  scale_shape_manual(values = c(23)) + 
  theme_bw()+ 
  scale_x_continuous(limits = c(1, 20)) +
  geom_label_repel(data = s6_DID3 %>% filter(state %in% c(3,4)), 
                   aes(y = mean_1_4, x = 2.5, label = paste("mean_y:", mean_1_4), col = state), show.legend = F) +
  geom_label_repel(data = s6_DID3 %>% filter(state %in% c(3,4)), 
                   aes(y = mean_5_11, x = 8, label = paste("mean_y:", mean_5_11), col = state), show.legend = F)

s6_comp1 + s6_comp2 + s6_comp3 + s6_comp4 + plot_layout(guides = "collect")
```

**Contrast 1:**

* Pre-post difference for never-treated state 1 is: 43.5-13.5=30
* Pre-post difference for never-treated state 2 is: 44.5-14.5=30
* Implying the average pre-post difference equals 30 for the never-treated states
* Pre-post difference for treated state 3 is 57-16.5 = 40.5
* $DID_{3 vs 1,2} = 40.5-30 = 10.5$

**Contrast 2:**

* Pre-post difference for never-treated state 1 is: 54-24=30
* Pre-post difference for never-treated state 2 is: 55-25=30
* Implying the average pre-post difference equals 30 for the never-treated states
* Pre-post difference for treated state 4 is 70-33= 37
* $DID_{4 vs 1,2} = 37-30 = 7$

**Contrast 3:**

* Pre-post difference for later-treated state 4 is: 39-22.5=16.5
* Pre-post difference for earlier-treated state 3 is: 39-16.5=22.5
* $DID_{3 vs 4} = 22.5-16.5 = 6$

**Contrast 4:**

* Pre-post difference for earlier-treated state 3 is: 71-39=32
* Pre-post difference for later-treated state 4 is: 70-39=31
* $DID_{4 vs 3} = 31-32 = -1$

Contrasts 1 and 2 are okay because they are clean comparisons between never-treated
and treated states. Contrasts 3 and 4 are trickier. Contrast 3 compares the 
earlier treated state to the later treated state. It is okay because parallel
trends holds and it only uses the time before the later state is treated to 
inform the estimation. Contrast 4 is the problem -- it uses post-treatment time
from state 3 as the "pre" time for the comparison. The issue is that this post
time includes the effects of the treatment, and since the effect is dynamic it
does not satisfy the parallel trends assumption. However this contrast still 
contributes to the TWFE regression estimate. To see this, we first calculate the
TWFE regression estimate and then use the Goodman Bacon decomposition to see how 
much weight each contrast contributes to the TWFE estimate. 

## Calculation of summary measures of the causal effect

In the previous scenarios, it has been relatively straightforward to identify 
the true causal effect that we would like to estimate. With dynamic effects, 
there are a few possibilities:

**Time-specific dynamic effects**: Calculate the causal effect of the policy at 
each time post-policy change. To see how these are calculated, see columns I and 
J in the "scen6" sheet of the Excel spreadsheet containing the imported data. 
Column J corresponds to the difference between the observed outcome (after
the policy change) and the counterfactual outcome had the treated state not been
treated.  This table summarizes the causal effect over time since treatment:

|Time since policy change   | Causal effect of the policy  |
|:-------------------------:|:----------------------------:|
|1                          | 3    |
|2                          | 4    |
|...                        | ...  |
|18                         | 18   |

This is the case for both the earlier- and the later- treated state, implying that
the ATT at the first time point equals 3, and so on (e.g., these are averages 
across the two treated states). When estimating the effects dynamically, these 
are the time-since-treatment-specific parameters we aim to estimate.

You may prefer a summary estimate, that aggregates across all post-treatment 
time into one number. Three possible ways to summarize into one number are as follows:

```{r echo=F}
blue_hex <- "#2885C2"
orange_hex <- "#fcba03"
green_hex <- "#28C269"
```

`r emo::ji("blue_book")` `r colorize("Causal Effect A", blue_hex)` 

Take an average of the estimated effects across the treated units:

$\frac{\text{Number in adoption cohort 1}}{\text{Number of treated units}} \times ATT_{adoption cohort 1} + \frac{\text{Number in adoption cohort 2}}{\text{Number of treated units}} \times ATT_{adoption cohort 2}$

$\frac{1}{2}\times 10.5 + \frac{1}{2}\times 7 = 8.75$

<br>
<br>

`r emo::ji("orange_book")` `r colorize("Causal Effect B", orange_hex)` 

Take the average of the causal effects across all the time points:

$$\frac{ATT_{t=1} + ATT_{t=2} +...+ ATT_{t=16}}{\text{Number of post-treatment times}} = \frac{3 + 4 + ... + 18}{16} = \frac{168}{16} = 10.5$$
<br>
<br>

`r emo::ji("green_book")` `r colorize("Causal Effect C", green_hex)` 

Take a weighted average of the causal effects, where the weights correspond to 
the number of units treated at each time point:
   
   $$\frac{2\times{ATT_{t=1}} +2\times{ATT_{t=2}} + ... + 2\times{ATT_{t=9} + ATT_{t=10} + ... ATT_{t=16}}}{\text{Total number of state-time points}}$$
   
   $$\frac{2\times(3+4+...+11) + (12+13+...+18)}{25} = 9.24$$
<br>
<br>

## TWFE Regression Model

```{r}
s6_mod <- lm(outcome ~ policy + state + factor(time), 
             data = s6)
tidy(s6_mod)
```

The coefficient of the policy term equals `r s6_mod$coefficients["policy1"] %>% round(2)`.
This is smaller than any of `r emo::ji("blue_book")` `r colorize("Causal Effect A", blue_hex)` , `r emo::ji("orange_book")` `r colorize("Causal Effect B", orange_hex)` , or `r emo::ji("green_book")` `r colorize("Causal Effect C", green_hex)`. To see how the TWFE
came to be this number, we use the Goodman Bacon decomposition to see how much
weight each of the contrasts contributes to the effect estimate:

## Goodman Bacon Decomposition

```{r}
s6 %<>% mutate(state_n = as.numeric(as.character(state)),
               policy_n = as.numeric(as.character(policy)))

s6_bacon <- bacon(outcome ~ policy_n,
      data = s6,
      id_var = "state_n",
      time_var = "time")
```

It is more helpful to view the four contrasts separately:

```{r}
s6_bacon
```

The estimates of the treatment effects for each contrast are as we
calculated them above. Note that `r round(s6_bacon$weight[3]*100)`% of the 
weight of the TWFE estimate is on Contrast 4 -- the one making the improper 
comparison between an earlier treated and a later treated state where parallel
trends does not hold.

We can also confirm that you get the TWFE estimate by taking the weighted 
average of the Goodman-Bacon decomposition components:

```{r}
#see the TWFE estimate
sum(s6_bacon$estimate*s6_bacon$weight)
```

The decomposition shows that the TWFE regression estimate is biased because it 
incorporates a contrast that we would not want to make in practice between an 
earlier treated and a later treated group. To overcome this, we use one of the 
new estimators. Consider the Group-Time ATT to start.

## Group-Time ATT Estimator

Like in the earlier examples we start by running the `att_gt()` function. Unlike
before, we display the output from this step using `summary()`. This output 
shows the estimated ATT for each combination of treated state and time. The time is long
because it includes estimates for pre-policy time, which helps with the 
evaluation of the parallel trends assumption or to see if there are any lead 
effects ("anticipation") of the treatment on the outcome. You wouldn't usually 
report this entire table, but it worth showing here to see how the estimated 
effect is dynamic and that decisions need to be make about how to report dynamics\
effects including whether or not to aggregate the effect, and if so, at what level.

```{r, warning=F}
s6_cs <- att_gt(yname = "outcome", 
             tname = "time", 
             idname = "state_n", 
             gname = "time_first_treat", 
             data = s6, 
             control_group = "notyettreated",
             anticipation = 0)


summary(s6_cs)
```

Callaway and Sant'Anna provide many options for aggregating the group-time 
effects. The simplest option is to specify `type = simple` in the `attge()` function.
This estimate considers only the contrasts with a never-treated state (i.e., 
Comparisons 1 and 2 in the figure above) and combines them into a weighted 
average, where the weights correspond to each adoption cohort's time spent in 
the post-treatment period. For contrast 1, there are 16 time periods post 
treatment and for contrast 2, there are 9 periods post-treatment. Thus the 
weighted average is: $10.5\times(16/25) + 7\times(9/25)=$ `r 10.5*(16/25) + 7*(9/25)`.
Note that this corresponds to `r emo::ji("green_book")` `r colorize("Causal Effect C", green_hex)` calculated in 
Section 8.2 above.

```{r}
#aggregate the group time average treatment effects
#type = "simple": weighted average of all group-time average treatment effects
#with weights proportional to the group size
s6_cs_ag <- aggte(s6_cs, type="simple")
summary(s6_cs_ag)
```

Alternatively, we can specify `type = "group"` to get separate effect estimates 
according to time of implementation. Note that `group` denotes the time of 
the policy's introduction for the treated states.

```{r}
s6_cs_ag2 <- aggte(s6_cs, type = "group")
summary(s6_cs_ag2)
```

The output also displays an estimate of the Overall ATT, equal to `r s6_cs_ag2$overall.att`.
This estimate is different from the one estimated `where type = "simple"`, and is 
equal to `r emo::ji("blue_book")` `r colorize("Causal Effect A", blue_hex)`.
Thus, the researcher may want to estimate the ATT
using this method if they prefer these weights over the weights specified by the
previous model.

You can also estimate the dynamic effect separately for each time since the 
treatment was introduced. Remember that this effect estimation is also done for 
pre-treatment time, so don't be surprised by all the rows in the outputted table!

```{r}
s6_cs_ag3 <- aggte(s6_cs, type="dynamic")
summary(s6_cs_ag3)
```

Again, the Overall ATT effect estimate is different from the other two. Here, it 
is a simple average of all effects in the post-treatment time. This is equal to 
$(3 + 4 + ... + 18)/16 = 10.5$, which equals `r emo::ji("orange_book")` `r colorize("Causal Effect B", orange_hex)`.

If you are more interested in the dynamic effect over time, it is  helpful to 
plot the estimates using the `ggdid()` function:

```{r}
ggdid(s6_cs_ag3)
```

Lastly, you can use `type = "calendar"` to aggregate the effects over calendar
time. Epidemiologically, this is not sensible under the context of dynamic effects
because it is mixing effect estimates across different times since treatment
was introduced. In some cases, only one comparison is contributing to the estimation
(e.g., in calendar time periods where only one group has introduced the treatment), 
while at other points, two comparisons contribute. But this "knowledge" is lost
in the presentation. We don't show the output from using `type = "calendar"` but
include the code below in case it makes sense for your setting.

```{r, eval=F}
#calendar=time specific
#not recommended for this setting...but Callaway and Sant'Anna say they prefer
#it here https://bcallaway11.github.io/did/articles/did-basics.html
s6_cs_ag4 <- aggte(s6_cs, type = "calendar")
summary(s6_cs_ag4)
ggdid(s6_cs_ag4)
```

## Target Trial Estimator

We can also estimate the effects using the Target Trial estimator. This time, we
start with the `fit_event_jack()` function which gives an estimate for each time
since treatment. This estimator yields the same estimates as the Group Time ATT
approach.  

```{r}
s6_bm <- fit_event_jack(outcome_var = "outcome", 
                            date_var = "time_as_date", 
                            unit_var = "state",
                            policy_var = "time_first_trt_date", 
                            data = s6, 
                            max_time_to = 10e7)


s6_bm_ave <- s6_bm %>% filter(cohort == "average")

s6_bm_ave %<>% mutate(lb = estimate - 1.96*se,
                      ub = estimate + 1.96*se)

ggplot(s6_bm_ave, aes(x = event_time, y = estimate)) + 
  geom_hline(yintercept = 0, lty = 2) +
  geom_point(aes(col = event_time >= 0)) + 
  geom_linerange(aes(ymin = lb, ymax = ub, col = event_time >= 0)) + 
  labs(y = "Estimate", x = "Event time") + 
  theme_bw() + 
  scale_color_discrete(labels=c('pre', 'post')) +
  theme(legend.title=element_blank(), legend.position = "bottom")
```

To summarize the dynamic effects into one aggregated effect estimate
we use the `fit_event_jack_sum()` function:

```{r}
s6_bm2 <- fit_event_jack_sum(outcome_var = "outcome", 
                            date_var = "time_as_date", 
                            unit_var = "state",
                            policy_var = "time_first_trt_date", 
                            data = s6, 
                            max_time_to = 10e7)

s6_bm2$estimate
```

The aggregated effect estimate equals `r s6_bm2$estimate`, equivalent to the 
Overall ATT from the Group-Time estimator when `type = "dynamic"` and to 
`r emo::ji("orange_book")` `r colorize("Causal Effect B", orange_hex)`

## TWFE with `time_since_policy` specification

But what if we model TWFE with the `time_since_change` indicators?

```{r}
s6_mod2 <- lm(outcome ~ time_since_policy + state + factor(time), 
             data = s6)
tidy(s6_mod2) %>% filter(str_detect(term, "time_since")) %>% 
  mutate(time = as.numeric(gsub("time_since_policy", "", term))) %>% 
  arrange(time) 
```

The regression model still works! The estimates from the policy indicator 
variables equal those estimated by the Group-Time estimator when specified using 
`type = "dynamic"` and the Target Trial approach, which are all equivalent to the
time-since-treatment-specific parameters we identified earlier.

## Summary

When the treatment effect is staggered and dynamic, you can still 
capture the effect estimate using a TWFE model so long as the policy effect is 
modeled using the `time_since_policy` variable. The key question for the 
researcher is to identify the parameter of interest -- are you interested in 
estimating a dynamic effect, or does a parameter that summarizes over treatment
time make sense? 

**Recommendation:** When there are multiple time periods, start by 
estimating a dynamic effect to see if the model supports its presence (i.e., 
does the effect change over time or is it constant?). If the effect appears 
dynamic, this is important because it is indicative of how the policy operates 
after being rolled out. If there is no strong support for a dynamic effect, then
consider estimating the effects separately by timing of introduction if that is 
sensible for the policy change under study (i.e., if there are only a few 
separate time points), or estimating one overall summary parameter.

# Scenario 7 (4 states, staggered timing, heterogeneous effects)

Scenario 7 is similar to Scenario 5 except now the treatment effect is different for the two treated states, i.e., it is heterogeneous. 

```{r}
# here we also specify the range of the data to be read into R because we don't
# want to include other information included in this sheet
s7 <- read_xlsx(here("data", "scenarios.xlsx"), sheet = "scen7", range = "A1:H81",
                col_types = c("text", "numeric", "text", "numeric", "text", "numeric",
                              "date", "date"))
```

## Visualization of Scenario 7

```{r, echo=F}
s7 %<>% mutate(ever_trt = case_when(state %in% c(3, 4) ~ "treated", 
                                    state %in% c(1, 2) ~ "untreated"))
ggplot(s7, aes(x = time, y = outcome)) + 
  geom_line(aes(col = factor(state))) + 
  geom_point(aes(fill = factor(state), pch = ever_trt)) + 
  labs(title = "Scenario 7 (Hetergeneous)") +
  geom_vline(aes(xintercept = 4.5), lty = 2, col = "#005a32") + 
  geom_vline(aes(xintercept = 11.5), lty = 2, col = "#99000d") +
  scale_fill_manual(values = c("#a6cee3","#1f78b4","#005a32", "#99000d")) +
  scale_color_manual(values = c("#a6cee3","#1f78b4","#005a32", "#99000d")) +
  scale_shape_manual(values = c(23, 21)) + 
  theme_bw()

```

**Visualization of all comparisons made by TWFE regression**

```{r, echo=F}
s7_mean_1_4 <- s7 %>% filter(time < 5) %>%
  group_by(state) %>%
  summarise(mean_1_4 = mean(outcome))

s7_mean_5_20 <- s7 %>% filter(time >= 5) %>%
  group_by(state) %>%
  summarise(mean_5_20 = mean(outcome))

s7_DID1 <- bind_cols(s7_mean_1_4, s7_mean_5_20 %>% select(-state)) %>%
  mutate(time_diff = mean_5_20 - mean_1_4)


s7_mean_1_11 <- s7 %>% filter(time < 12) %>%
  group_by(state) %>%
  summarise(mean_1_11 = mean(outcome))

s7_mean_12_20 <- s7 %>% filter(time >= 12) %>%
  group_by(state) %>%
  summarise(mean_12_20 = mean(outcome))

s7_DID2 <- bind_cols(s7_mean_1_11, 
                     s7_mean_12_20 %>% select(-state)) %>%
  mutate(time_diff2 = mean_12_20 - mean_1_11)

s7_mean_5_11 <- s7 %>% filter(time >= 5 & time < 12) %>%
  group_by(state) %>%
  summarise(mean_5_11 = mean(outcome))

s7_DID3 <- bind_cols(s7_mean_1_4, 
                     s7_mean_5_11 %>% select(-state)) %>%
  mutate(time_diff3 = mean_5_11 - mean_1_4)

s7_DID4 <- bind_cols(s7_mean_5_11, 
                     s7_mean_12_20 %>% select(-state)) %>%
  mutate(time_diff4 = mean_12_20 - mean_5_11)
```

```{r, echo = F, fig.height = 8, fig.width = 10}
s7_comp1 <- ggplot(s7 %>% filter(state %in% c(1, 2, 3)), aes(x = time, y = outcome)) + 
  geom_line(aes(col = factor(state))) + 
  geom_point(aes(fill = factor(state), pch = ever_trt)) + labs(title = "A) Contrast 1 (Treated vs. never-treated)") +
  geom_vline(aes(xintercept = 4.5), lty = 2) +
  scale_color_manual(values = c("#a6cee3","#1f78b4","#005a32")) +
  scale_fill_manual(values = c("#a6cee3","#1f78b4","#005a32")) +
  theme_bw() + 
  scale_x_continuous(limits = c(1, 20)) +
  scale_shape_manual(values = c(23, 21)) + 
  geom_label_repel(data = s7_DID1 %>% filter(state %in% c(1,2,3)), 
                  aes(y = mean_1_4, x = 2.5, label = paste("mean_y:", mean_1_4), col = state), show.legend = F) +
  geom_label_repel(data = s7_DID1 %>% filter(state %in% c(1,2,3)), 
                  aes(y = mean_5_20, x = 12.5, label = paste("mean_y:", mean_5_20), col = state), show.legend = F)
 
s7_comp2 <- ggplot(s7 %>% filter(state %in% c(1, 2, 4)), aes(x = time, y = outcome)) + 
  geom_line(aes(col = factor(state))) +
  geom_point(aes(fill = factor(state),  pch = ever_trt)) + labs(title = "B) Contrast 2 (Treated vs. never-treated)") +
  geom_vline(aes(xintercept = 11.5), lty = 2) +
  scale_color_manual(values = c("#a6cee3","#1f78b4","#99000d")) +
  scale_fill_manual(values = c("#a6cee3","#1f78b4","#99000d")) +
  theme_bw()+ 
  scale_x_continuous(limits = c(1, 20)) +
  scale_shape_manual(values = c(23, 21)) + 
  geom_label_repel(data = s7_DID2 %>% filter(state %in% c(1,2,4)), 
                   aes(y = mean_1_11, x = 6, label = paste("mean_y:", mean_1_11), col = state), show.legend = F) +
  geom_label_repel(data = s7_DID2 %>% filter(state %in% c(1,2,4)), 
                   aes(y = mean_12_20, x = 16, label = paste("mean_y:", mean_12_20), col = state), show.legend = F)

s7_comp4 <- ggplot(s7 %>% filter(state %in% c(3, 4), time >= 5), aes(x = time, y = outcome)) +  
  geom_line(aes(col = factor(state))) + 
  geom_point(aes(fill = factor(state), pch = ever_trt)) + labs(title = "C) Contrast 4 (Later vs. earlier-treated)") +
  geom_vline(aes(xintercept = 11.5), lty = 2) +
  scale_color_manual(values = c("#005a32", "#99000d")) +
  scale_fill_manual(values = c("#005a32", "#99000d")) +
  scale_shape_manual(values = c(23)) + 
  theme_bw()+ 
  scale_x_continuous(limits = c(1, 20)) +
  geom_label_repel(data = s7_DID4 %>% filter(state %in% c(3,4)), 
                   aes(y = mean_5_11, x = 8, label = paste("mean_y:", mean_5_11), col = state), show.legend = F) +
  geom_label_repel(data = s7_DID4 %>% filter(state %in% c(3,4)), 
                   aes(y = mean_12_20, x = 16, label = paste("mean_y:", mean_12_20), col = state), show.legend = F)

s7_comp3 <- ggplot(s7 %>% filter(state %in% c(3, 4), time < 12), aes(x = time, y = outcome)) +   
  geom_line(aes(col = factor(state))) + 
  geom_point(aes(fill = factor(state), pch = ever_trt)) + labs(title = "D) Contrast 3 (Earlier vs. later-treated)") +
  geom_vline(aes(xintercept = 4.5), lty = 2) +
  scale_color_manual(values = c("#005a32", "#99000d")) +
  scale_fill_manual(values = c("#005a32", "#99000d")) +
  scale_shape_manual(values = c(23)) + 
  theme_bw()+ 
  scale_x_continuous(limits = c(1, 20)) +
  geom_label_repel(data = s7_DID3 %>% filter(state %in% c(3,4)), 
                   aes(y = mean_1_4, x = 2.5, label = paste("mean_y:", mean_1_4), col = state), show.legend = F) +
  geom_label_repel(data = s7_DID3 %>% filter(state %in% c(3,4)), 
                   aes(y = mean_5_11, x = 8, label = paste("mean_y:", mean_5_11), col = state), show.legend = F)

s7_comp1 + s7_comp2 + s7_comp3 + s7_comp4 + plot_layout(guides = "collect")
```

**Contrast 1:**

* Pre-post difference for never-treated state 1 is: 43.5-13.5=30
* Pre-post difference for never-treated state 2 is: 44.5-14.5=30
* Implying the average pre-post difference equals 30 for the never-treated states
* Pre-post difference for treated state 3 is 52.5-16.5 = 36
* $DID_{3 vs 1,2} = 36-30 = 6$

**Contrast 2:**

* Pre-post difference for never-treated state 1 is: 54-24=30
* Pre-post difference for never-treated state 2 is: 55-25=30
* Implying the average pre-post difference equals 30 for the never-treated states
* Pre-post difference for treated state 4 is 67-33= 34
* $DID_{4 vs 1,2} = 34-30 = 4$

**Contrast 3:**

* Pre-post difference for later-treated state 4 is: 39-22.5=16.5
* Pre-post difference for earlier-treated state 3 is: 39-16.5=22.5
* $DID_{3 vs 4} = 22.5-16.5 = 6$

**Contrast 4:**

* Pre-post difference for earlier-treated state 3 is: 63-39=24
* Pre-post difference for later-treated state 4 is: 67-39=28
* $DID_{4 vs 3} = 28-24 = 4$

Contrasts 1 and 2 are definitely okay because they are clean comparisons between never-treated and treated states. Contrasts 3 and 4 are trickier, however, we can see from the diagram that parallel trends is still satisfied. So, even though 
the model uses a previously treated state as a control, this is okay because the causal effect of the treatment was heterogeneous and does not lead to a violation of the parallel trends assumption. Thus, we are comfortable with all contrasts 
contributing to the TWFE regression estimate. To see how much weight is put on 
each one, we use the Goodman Bacon decomposition, but first we consider the 
different causal effects that can be calculated.

## Calculation of summary measures of the causal effect

Once the setting includes both heterogeneous effects and staggered timing, there
is a question of how to aggregate the causal effect estimates across multiple
treated units into one estimate. Here are three causal effects that could be 
calculated:

```{r echo=F}
blue_hex <- "#2885C2"
orange_hex <- "#fcba03"
green_hex <- "#28C269"
```


`r emo::ji("blue_book")` `r colorize("Causal Effect A", blue_hex)` 

Take an average of the estimated effects across the treated units: 

$\frac{\text{Number in adoption cohort 1}}{\text{Number of treated units}} \times ATT_{adoption cohort 1} + \frac{\text{Number in adoption cohort 2}}{\text{Number of treated units}} \times ATT_{adoption cohort 2}$

$\frac{1}{2} \times 6 + \frac{1}{2} \times 4 = 5$
<br>
<br>

`r emo::ji("orange_book")` `r colorize("Causal Effect B", orange_hex)` 

Take an average of the effects across all post-treatment time points:

$\frac{ATT_{t=1} + ATT_{t=2} + ... + ATT_{t=16}}{\text{Number of posttreatment times}}$

$\frac{[5\times9] +[6\times7]}{16}=5.43$
<br>
<br>

`r emo::ji("green_book")` `r colorize("Causal Effect C", green_hex)` 

Take a weighted average of the post-treatment-time-specific effects, where the 
weights correspond to the number of units treated at each time point:

   $\frac{2\times{[ATT_{t=1}} +{ATT_{t=2}} + ... + {ATT_{t=9}] + 1\times[{ATT_{t=10} + ... +ATT_{t=16}}}]}{\text{Total number of state-time points}}$
   
   $\frac{2\times(5+5+...+5) + 1\times{(6+...+6)}}{25} = 5.28$
<br>
<br>
   
Each of these causal effects are valid measures to calculate and all come with 
strengths and weaknesses. The researcher needs to decide which one to calculate.
Let's first see how the estimate from the TWFE model compares.

## TWFE Regression Model

```{r}
s7_mod <- lm(outcome ~ policy + state + factor(time), 
             data = s7)
tidy(s7_mod)
```

The coefficient of the policy term equals `r s7_mod$coefficients["policy1"] %>% round(2)`.
This is smaller than any of `r emo::ji("blue_book")` `r colorize("Causal Effect A", blue_hex)` , `r emo::ji("orange_book")` `r colorize("Causal Effect B", orange_hex)` , or `r emo::ji("green_book")` `r colorize("Causal Effect C", green_hex)`.
To see how the TWFE came to be this number, we use the Goodman Bacon 
decomposition to see how much weight each of the contrasts contributes to the 
effect estimate.

## Goodman Bacon Decomposition

```{r}
s7 %<>% mutate(state_n = as.numeric(as.character(state)),
               policy_n = as.numeric(as.character(policy)))

s7_bacon <- bacon(outcome ~ policy_n,
      data = s7,
      id_var = "state_n",
      time_var = "time")
```

It is more helpful to view the four contrasts separately:

```{r}
s7_bacon
```

The estimates of the treatment effects for each contrast are as we
calculated them above. However, the TWFE's estimate of 
`r sum(s7_bacon$estimate*s7_bacon$weight) %>% round(2)`,
is pulled towards 4, because the combined weight put on
the effect estimate of 4 is higher than the combined weight put on the effect
estimate of 6. This leads to an effect estimate from TWFE that is smaller than 
any of the causal effect estimates.

The TWFE regression estimate is estimating a different causal estimand than any 
of the three with initially proposed. The new proposed estimators overcome this
issue and are considered next.

## Group-Time ATT Estimator

Like in the earlier examples we start by running the `att_gt()` function. 

```{r, warning=F}
s7_cs <- att_gt(yname = "outcome", 
             tname = "time", 
             idname = "state_n", 
             gname = "time_first_treat", 
             data = s7, 
             control_group = "notyettreated",
             anticipation = 0)
```

Callaway and Sant'Anna provide many options for aggregating the group-time 
effects. The simplest option is to specify `type = simple` in the `attge()` function.
This estimate considers only the contrasts with a never-treated state (i.e., 
Comparisons 1 and 2 in the figure above) and combines them into a weighted 
average, where the weights correspond to each adoption cohort's time spent in 
the post-treatment period. For contrast 1, there are 16 time periods post 
treatment and for contrast 2, there are 9 periods post-treatment. Thus the 
weighted average is: $6\times(16/25) + 4\times(9/25)=$ `r 6*(16/25) + 4*(9/25)`.
This is the same as `r emo::ji("green_book")` `r colorize("Causal Effect C", green_hex)` calculated above.

```{r}
#aggregate the group time average treatment effects
#type = "simple": weighted average of all group-time average treatment effects
#with weights proportional to the group size
s7_cs_ag <- aggte(s7_cs, type="simple")
summary(s7_cs_ag)
```

Alternatively, we can specify `type = "group"` to get separate effect estimates 
according to time of implementation. In the output `Group` denotes the time of 
the policy's introduction for the treated states.

```{r}
s7_cs_ag2 <- aggte(s7_cs, type = "group")
summary(s7_cs_ag2)
```

The output also displays an estimate of the Overall ATT, equal to `r s7_cs_ag2$overall.att`.
This estimate is different from the one estimated `where type = "simple"`. Here,
the estimate is a weighted average, with weights proportional to the number of 
units in each adoption cohort (e.g., $(1/2)\times 6 + (1/2) \times 4=$ `r s7_cs_ag2$overall.att`). This is equal to `r emo::ji("blue_book")` `r colorize("Causal Effect A", blue_hex)` calculated above.

Alternatively, we can specific `type = "dynamic"` to get separate effect estimates
for each time period. We can also see that the Overall ATT from this call is 
equal to `r emo::ji("orange_book")` `r colorize("Causal Effect B", orange_hex)` calculated above.

```{r}
s7_cs_ag2 <- aggte(s7_cs, type = "dynamic")
summary(s7_cs_ag2)
```

## Target Trial Estimator

We can also estimate the effects using the Target Trial estimator. This time, we
start with the `fit_event_jack()` function which gives an estimate for each time
since treatment. 

```{r}
s7_bm <- fit_event_jack(outcome_var = "outcome", 
                            date_var = "time_as_date", 
                            unit_var = "state",
                            policy_var = "time_first_trt_date", 
                            data = s7, 
                            max_time_to = 10e7)

s7_bm_ave <- s7_bm %>% filter(cohort == "average")

s7_bm_ave %<>% mutate(lb = estimate - 1.96*se,
                      ub = estimate + 1.96*se)
```

The plot below shows that the time-specific estimates equal 5 when there are
two states contributing to the estimate (one with a causal effect of 4 and the 
other with a causal effect of 6) and 6 when only the early-introduction state 
contributes to the causal effect estimate.

```{r}
ggplot(s7_bm_ave, aes(x = event_time, y = estimate)) + 
  geom_hline(yintercept = 0, lty = 2) +
  geom_point(aes(col = event_time >= 0)) + 
  geom_linerange(aes(ymin = lb, ymax = ub, col = event_time >= 0)) + 
  labs(y = "Estimate", x = "Event time") + 
  theme_bw() + 
  scale_color_discrete(labels=c('pre', 'post')) +
  theme(legend.title=element_blank(), legend.position = "bottom")
```

To summarize the effects into one aggregated effect estimate
we use one of the `fit_event_jack_sum()`, `fit_event_jack_sum_hte()`, or 
`fit_event_jack_sum_C()` functions. The functions estimate different causal 
effects, so choose the one that corresponds in the effect estimate you are
interested in.

Let's calculate the aggregated estimate using `fit_event_jack_sum()` first:

```{r}
s7_bm2 <- fit_event_jack_sum(outcome_var = "outcome", 
                            date_var = "time_as_date", 
                            unit_var = "state",
                            policy_var = "time_first_trt_date", 
                            data = s7, 
                            max_time_to = 10e7)

s7_bm2$estimate
```

The aggregated effect estimate using `fit_event_jack_sum` equals `r s7_bm2$estimate`, equivalent to the `r emo::ji("orange_book")` `r colorize("Causal Effect B", orange_hex)`.

We can compare this to the aggregated effect estimate from `fit_event_jack_sum_hte()`:

```{r}
s7_bm3 <- fit_event_jack_sum_hte(outcome_var = "outcome", 
                            date_var = "time_as_date", 
                            unit_var = "state",
                            policy_var = "time_first_trt_date", 
                            data = s7, 
                            max_time_to = 10e7)

s7_bm3$estimate
```

The aggregated effect estimate using `fit_event_jack_sum_hte()` equals `r s7_bm3$estimate`, equivalent to the `r emo::ji("orange_book")` `r colorize("Causal Effect A", blue_hex)`.

Finally, we can compare this to the aggregated effect estimate from `fit_event_jack_sum_C()`: 

```{r}
s7_bm4 <- fit_event_jack_sum_C(outcome_var = "outcome", 
                            date_var = "time_as_date", 
                            unit_var = "state",
                            policy_var = "time_first_trt_date", 
                            data = s7, 
                            max_time_to = 10e7)

s7_bm4$estimate
```

The aggregated effect estimate using `fit_event_jack_sum_C()` equals `r s7_bm4$estimate`, equivalent to the `r emo::ji("green_book")` `r colorize("Causal Effect C", green_hex)`.

## Summary

When the treatment effect is staggered and heterogeneous, the TWFE estimate aggregates
the heterogeneous effects using weights that are calculated by the model and
not concordant with weights researchers would intuitively choose. In this 
example, this led to an effect estimate that was lower than the three causal 
effect estimates we aimed to estimate. Thus, TWFE performs unfavorably when 
effects are heterogeneous across adoption cohorts. 

**Recommendation:** Use the `aggte()` function with `type = "group"` to estimate 
effects separately for each adoption cohort alongside confidence intervals. Examine
the difference in effects across adoption cohorts and their associated precision, 
remembering that the number of units contributing to each adoption cohort will
affect the width of its confidence interval, which may make it difficult to make
conclusive statements about heterogeneity across adoption cohorts in the presence
of limited data. 


# Scenario 8 (4 states, staggered timing, dynamic and heterogeneous treatment effects)

Scenario 8 combines the complexities across Scenarios 6 and 7. In this scenario,
the state that implements the policy change first has a stronger treatment 
effect (i.e., a steeper change in slope).

```{r}
s8 <- read_xlsx(here("data", "scenarios.xlsx"), sheet = "scen8", range = "A1:H81", 
                col_types = c("text", "numeric", "text", "numeric", "text", "numeric",
                              "date", "date"))
```

## Visualization of Scenario 8

```{r, echo=F}

control1_blue <- "#a6cee3"
control2_blue <-"#1f78b4"
treated5_green <- "#005a32"
treated12_red <- "#99000d"


s8 %<>% mutate(ever_trt = case_when(state %in% c(3, 4) ~ "treated", 
                                    state %in% c(1, 2) ~ "untreated")
               )

ggplot(s8, aes(x = time, y = outcome)) + 
  geom_point(aes(fill = factor(state), pch = ever_trt)) +
  labs(title = "Scenario 8 (Staggered, dynamic, and heterogeneous)") +
  geom_line(aes(col = factor(state))) + 
  geom_vline(aes(xintercept = 4.5), lty = 2, col = treated5_green) + 
  geom_vline(aes(xintercept = 11.5), lty = 2, col = treated12_red) +
  scale_color_manual(values = c(control1_blue, control2_blue, treated5_green, treated12_red)) +
  scale_fill_manual(values = c(control1_blue, control2_blue, treated5_green, treated12_red)) +
  scale_shape_manual(values = c(23, 21)) + 
  theme_bw()
```

**Visualization of all comparisons made by TWFE regression**

```{r, echo=F}
s8_mean_1_4 <- s8 %>% filter(time < 5) %>%
  group_by(state) %>%
  summarise(mean_1_4 = mean(outcome))

s8_mean_5_20 <- s8 %>% filter(time >= 5) %>%
  group_by(state) %>%
  summarise(mean_5_20 = mean(outcome))

s8_DID1 <- bind_cols(s8_mean_1_4, s8_mean_5_20 %>% select(-state)) %>%
  mutate(time_diff = mean_5_20 - mean_1_4)

s8_mean_1_11 <- s8 %>% filter(time < 12) %>%
  group_by(state) %>%
  summarise(mean_1_11 = mean(outcome))

s8_mean_12_20 <- s8 %>% filter(time >= 12) %>%
  group_by(state) %>%
  summarise(mean_12_20 = mean(outcome))

s8_DID2 <- bind_cols(s8_mean_1_11, 
                     s8_mean_12_20 %>% select(-state)) %>%
  mutate(time_diff2 = mean_12_20 - mean_1_11)

s8_mean_5_11 <- s8 %>% filter(time >= 5 & time < 12) %>%
  group_by(state) %>%
  summarise(mean_5_11 = mean(outcome))

s8_DID3 <- bind_cols(s8_mean_1_4, 
                     s8_mean_5_11 %>% select(-state)) %>%
  mutate(time_diff3 = mean_5_11 - mean_1_4)

s8_DID4 <- bind_cols(s8_mean_5_11, 
                     s8_mean_12_20 %>% select(-state)) %>%
  mutate(time_diff4 = mean_12_20 - mean_5_11)
```

```{r, echo = F, fig.height = 8, fig.width = 10}
s8_comp1 <- ggplot(s8 %>% filter(state %in% c(1, 2, 3)), aes(x = time, y = outcome)) +   
  geom_line(aes(col = factor(state))) + 
  geom_point(aes(fill = factor(state), pch = ever_trt)) + labs(title = "A) Contrast 1 (Treated vs. never-treated)") +
  geom_vline(aes(xintercept = 4.5), lty = 2, col = treated5_green) +
  geom_label_repel(data = s8_DID1 %>% filter(state %in% c(1,2,3)),
                  aes(y = mean_1_4, x = 2.5, label = paste("mean_y:", mean_1_4), col = state), show.legend = F) +
  geom_label_repel(data = s8_DID1 %>% filter(state %in% c(1,2,3)),
                  aes(y = mean_5_20, x = 12.5, label = paste("mean_y:", mean_5_20), col = state), show.legend = F) +
  scale_x_continuous(limits = c(1, 20))  + 
  scale_color_manual(values = c(control1_blue, control2_blue, treated5_green)) +
  scale_fill_manual(values = c(control1_blue, control2_blue, treated5_green)) +
  scale_shape_manual(values = c(21, 23)) + 
  theme_bw() 

s8_comp2 <- ggplot(s8 %>% filter(state %in% c(1, 2, 4)), aes(x = time, y = outcome)) +   
  geom_line(aes(col = factor(state))) + 
  geom_point(aes(fill = factor(state), pch = ever_trt)) + labs(title = "B) Contrast 2 (Treated vs. never-treated)") +
  geom_vline(aes(xintercept = 11.5), lty = 2, col = treated12_red) +
  geom_label_repel(data = s8_DID2 %>% filter(state %in% c(1,2,4)),
                   aes(y = mean_1_11, x = 6, label = paste("mean_y:", mean_1_11), col = state), show.legend = F) +
  geom_label_repel(data = s8_DID2 %>% filter(state %in% c(1,2,4)),
                   aes(y = mean_12_20, x = 16, label = paste("mean_y:", mean_12_20), col = state), show.legend = F) +
  scale_x_continuous(limits = c(1, 20))  + 
  scale_color_manual(values = c(control1_blue, control2_blue, treated12_red)) +
  scale_fill_manual(values = c(control1_blue, control2_blue, treated12_red)) +
  scale_shape_manual(values = c(21, 23)) + 
  theme_bw() 

s8_comp4 <- ggplot(s8 %>% filter(state %in% c(3, 4), time >= 5), aes(x = time, y = outcome)) +
  geom_line(aes(col = factor(state))) + 
  geom_point(aes(fill = factor(state), pch = ever_trt), show.legend = F) + labs(title = "C) Contrast 4 (Later vs. earlier-treated)") +
  geom_vline(aes(xintercept = 11.5), lty = 2, col = treated12_red) +
  geom_label_repel(data = s8_DID4 %>% filter(state %in% c(3,4)),
                   aes(y = mean_5_11, x = 8, label = paste("mean_y:", mean_5_11), col = state), show.legend = F) +
  geom_label_repel(data = s8_DID4 %>% filter(state %in% c(3,4)),
                   aes(y = mean_12_20, x = 16, label = paste("mean_y:", mean_12_20), col = state), show.legend = F) + 
  scale_x_continuous(limits = c(1, 20))  + 
  scale_color_manual(values = c(treated5_green, treated12_red)) +
  scale_fill_manual(values = c(treated5_green, treated12_red)) +
  scale_shape_manual(values = c(23)) + 
  theme_bw() 

s8_comp3 <- ggplot(s8 %>% filter(state %in% c(3, 4), time < 12), aes(x = time, y = outcome)) +   
  geom_line(aes(col = factor(state))) + 
  geom_point(aes(fill = factor(state), pch = ever_trt), show.legend = F) + labs(title = "D) Contrast 3 (Earlier vs. later-treated)") +
  geom_vline(aes(xintercept = 4.5), lty = 2, col = treated5_green) +
  geom_label_repel(data = s8_DID3 %>% filter(state %in% c(3,4)),
                   aes(y = mean_1_4, x = 2.5, label = paste("mean_y:", mean_1_4), col = state), show.legend = F) +
  geom_label_repel(data = s8_DID3 %>% filter(state %in% c(3,4)),
                   aes(y = mean_5_11, x = 8, label = paste("mean_y:", mean_5_11), col = state), show.legend = F) + 
  scale_x_continuous(limits = c(1, 20))  + 
  scale_color_manual(values = c(treated5_green, treated12_red)) +
  scale_fill_manual(values = c(treated5_green, treated12_red)) +
  scale_shape_manual(values = c(23)) + 
  theme_bw() 

s8_comp1 + s8_comp2 + s8_comp3 + s8_comp4 + plot_layout(guides = "collect")
```

**Contrast 1:**

* Pre-post difference for never-treated state 1 is: 43.5-13.5=30
* Pre-post difference for never-treated state 2 is: 44.5-14.5=30
* Implying the average pre-post difference equals 30 for the never-treated states
* Pre-post difference for treated state 3 is 64.5-16.5 = 48
* $DID_{3 vs 1,2} = 48-30 = 18$

**Contrast 2:**

* Pre-post difference for never-treated state 1 is: 54-24=30
* Pre-post difference for never-treated state 2 is: 55-25=30
* Implying the average pre-post difference equals 30 for the never-treated states
* Pre-post difference for treated state 4 is 68-33= 35
* $DID_{4 vs 1,2} = 35-30 = 5$

**Contrast 3:**

* Pre-post difference for later-treated state 4 is: 39-22.5=16.5
* Pre-post difference for earlier-treated state 3 is: 42-16.5=25.5
* $DID_{3 vs 4} = 25.5-16.5 = 9$

**Contrast 4:**

* Pre-post difference for earlier-treated state 3 is: 82-42=40
* Pre-post difference for later-treated state 4 is: 68-39=29
* $DID_{4 vs 3} = 29-40 = -11$

Similar to the previous scenario, parallel trends is satisfied for contrasts 1-3, 
so we can be okay with these contrasts contributing to the average effect estimate. 
Like last time, contrast 4 is the problem, and here the problem is intensified
because the "control" state -- which was treated in an earlier period -- is 
undergoing a large treatment effect in the "pre" period (times 5-11). This 
makes the pre-post difference in the control state larger than the pre-post difference
in the comparison state -- because the control state is still experiencing a stronger
(i.e., steeper slope) treatment effect than the state that is treated at time 12. 
This leads to a DID estimate for this group and time being relatively large, but
negative, even though the true effect is to increase the outcome.

## Calculation of summary measures of the causal effect 

1. **Time-specific dynamic effects**: To see how these are calculated, see 
columns I and J in the “scen7” sheet of the Excel spreadsheet containing the 
imported data. Column J corresponds to the difference between the observed 
outcome (after the policy change) and the counterfactual outcome had the treated
state not been treated. This table summarizes the causal effect over time since 
treatment separately for each treated state:

|Time since policy change   | Causal effect of the policy in earlier treated  | Causal effect of the policy in later treated  | Time-specific ATT |
|:-------------------------:|:----------------------------:|:----------------------------:| :------------------:|
|1                          | 3    | 1       | 2     |
|2                          | 5    | 2       | 3.5     |
|3                          | 7    | 3       | 5     |
|4                          | 9    | 4       | 6.5     |
|...                        | ...  | ...     | ...   |
|9                          | 19   | 9 (last observed time for later treated) | 14|
| 10                        | 21   | -       | 21    |
|...                        | ...  | -       | ...   |
|16                         | 33   | -       | 33    |

Here, the earlier- and later- treated states had different ATTs. So, we take
their average at each time point in the last column. In times 10 or larger, 
there is only one treated state, so the average is equal to that one state's 
causal effect. When estimating the effects dynamically, these are the time-since-treatment-specific parameters we aim to estimate.

You may prefer a summary estimate that aggregates across all post-treatment time
into one number. Three possible ways to summarize into one number are as follows:

`r emo::ji("blue_book")` `r colorize("Causal Effect A", blue_hex)` 

Take a simple average of the heterogeneous treatment effects:

$$\frac{ATT_{\text{3 vs 1,2}} + ATT_{\text{4 vs 1,2}}}{2} = \frac{18 + 5}{2} = 11.5$$
<br>
<br>

`r emo::ji("orange_book")` `r colorize("Causal Effect B", orange_hex)`

Take the average of the causal effects across all the time points:

$$\frac{ATT_{t=1} + ATT_{t=2} + ATT_{t=16}}{\text{Number of post-treatment times}} = \frac{2 + 3.5 + ... + 33}{16} = \frac{261}{16} = 16.3125$$
<br>
<br>

`r emo::ji("green_book")` `r colorize("Causal Effect B", green_hex)`

Take a weighted average of the causal effects, where the weights correspond to 
the number of units treated at each time point:

$$\frac{2\times ATT_{t=1} + 2\times ATT_{t=2} + ... + 2 \times ATT_{t=9} + ATT_{t=10} + ... + ATT_{t=16}}{\text{Number of post-treatment times}}$$

$$\frac{2 \times (2 + 3.5 + ... + 14) + (21 + 23 ... + 33)}{25} = 13.32$$
<br>
<br>

## TWFE Regression Model

Let's take a look at the regression output:

```{r}
s8_mod <- lm(outcome ~ policy + state + factor(time), 
             data = s8)
tidy(s8_mod)
```

The coefficient of the policy term equals `r s8_mod$coefficients["policy1"] %>% round(2)`.
This is smaller than any of `r emo::ji("blue_book")` `r colorize("Causal Effect A", blue_hex)` , `r emo::ji("orange_book")` `r colorize("Causal Effect B", orange_hex)` , or `r emo::ji("green_book")` `r colorize("Causal Effect C", green_hex)`. Why is the 
TWFE estimate so much lower? In the previous scenario we 
learned how the TWFE estimate considers each possible contrast between a treated
state a those untreated at the same time. The fourth
contrast in this setting did not satisfy the parallel trends assumption, but the
other three contrasts did. How much weight did the TWFE estimator put on each of
the contrasts? Let's consider the Goodman Bacon decomposition to see how 
much each contrast contributed to the TWFE estimate: 

## Goodman Bacon Decomposition

```{r}
s8 %<>% mutate(state_n = as.numeric(as.character(state)),
               policy_n = as.numeric(as.character(policy)))

s8_bacon <- bacon(outcome ~ policy_n,
      data = s8,
      id_var = "state_n",
      time_var = "time")
```

```{r}
s8_bacon
```

Notice that our fourth contrast (here shown in row 3 of the second table) 
contributes `r round(s8_bacon$weight[3]*100)`% of the weight to the estimate. We
want an estimator that does not use this contrast! 

Below we confirm the weighted estimate across the rows equals the TWFE estimate
from the regression:

```{r}
#see the TWFE estimate
sum(s8_bacon$estimate*s8_bacon$weight)
```

The TWFE estimator is influenced by the forbidden fourth contrast that doesn't 
meet the parallel trends assumption, so we'd like an estimator that doesn't
suffer from this concern.

## Group-Time ATT Estimator

Now that we know how to use the Callaway and Sant'Anna code, we can apply it to
this example as well. Let's start by running the `att_gt()` function. This
time we won't display the output from `summary()`, but feel free to uncomment 
that line in the R markdown document to take a peak:

```{r, warning=F}
s8_cs <- att_gt(yname = "outcome", 
             tname = "time", 
             idname = "state_n", 
             gname = "time_first_treat", 
             data = s8, 
             control_group = "notyettreated",
             anticipation = 0)

#summary(s8_cs)
```

Let's aggregate the ATTs using `type = simple`. Callaway and Sant'Anna's estimate
considers only the clean contrasts of 1 and 2 and combines them by weighting by 
the total time in the post-treatment period. For contrast 1, there are 16 
time periods post treatment and for contrast 2, there are 9 periods 
post-treatment. Thus this estimate is the weighted average: 
$18\times(16/25) + 5\times(9/25)=$ `r 18*(16/25) + 5*(9/25)` . Note that this 
is equal to `r emo::ji("green_book")` `r colorize("Causal Effect C", green_hex)`.

```{r}
#aggregate the group time average treatment effects
#type = "simple": weighted average of all group-time average treatment effects
#with weights proportional to the group size
s8_cs_ag <- aggte(s8_cs, type="simple")
summary(s8_cs_ag)
```

Alternatively, we can specify `type = "group"` to get separate effect estimates 
according to time of implementation and see that these match our by-hand calculations: 

```{r}
s8_cs_ag2 <- aggte(s8_cs, type = "group")
summary(s8_cs_ag2)
```

Note here that the Overall ATT is a simple average of the two groups (e.g., (18 + 5)/2 = 11.5), equal to `r emo::ji("blue_book")` `r colorize("Causal Effect A", blue_hex)`.

Alternatively, you can estimate the dynamic effect separately for each time 
since the treatment has been introduced. Remember that this effect estimation
is also done for pre-treatment time, so don't be alarmed by all the rows in this 
table!

```{r}
s8_cs_ag3 <- aggte(s8_cs, type="dynamic")
summary(s8_cs_ag3)
```

Note here that the Overall ATT is a simple average of all effects in the post-treatment 
time. This is equal to (2 + 3.5 + 5 + 6.5 + ... + 33)/16=16.31, which is equal 
to `r emo::ji("orange_book")` `r colorize("Causal Effect B", orange_hex)`.

Because the treatment effect is heterogeneous (the later treated state
has a smaller treatment effect than the earlier treated state) and because there
is less observed treated time for the later state, this means that the treatment
effect estimates for event times 0 through 8 combine across the two treated 
states but for times 9 and over those effect estimates are based only on the 
first treated state. Without knowing this, it looks like the treatment effect 
"jumps" between event times 8 and 9 and that there is a slope increase, but this 
is an artifact based on combining across states with heterogeneous effects with 
different lengths of observed treatment times.

We can also plot the effect estimates over time and see this jump and slope 
increase between event times 8 and 9. Note also the confidence interval estimates
that occurred for times 0 through 8 since there were two data points that could
be used to estimate standard errors.

```{r}
ggdid(s8_cs_ag3)
```

Here again we don't display the results using `type = "calendar"` but have included the code here in case you want to run it. 

```{r, eval=F}
s8_cs_ag4 <- aggte(s8_cs, type = "calendar")
summary(s8_cs_ag4)
ggdid(s8_cs_ag4)
```

## Target Trial Estimator

The code and output below show that the dynamic estimates using the Target Trial
approach are the same as those produced by the Group-Time ATT approach. 

```{r}
s8_bm <- fit_event_jack(outcome_var = "outcome", 
                        date_var = "time_as_date", 
                        unit_var = "state",
                        policy_var = "time_first_trt_date", 
                        data = s8, 
                        max_time_to = 10e7)

s8_bm_ave <- s8_bm %>% filter(cohort == "average")

s8_bm_ave %<>% mutate(lb = estimate - 1.96*se,
                      ub = estimate + 1.96*se)

ggplot(s8_bm_ave, aes(x = event_time, y = estimate)) + 
  geom_hline(yintercept = 0, lty = 2) +
  geom_point(aes(col = event_time >= 0)) + 
  geom_linerange(aes(ymin = lb, ymax = ub, col = event_time >= 0)) + 
  labs(y = "Estimate", x = "Event time") + 
  theme_bw() + 
  scale_color_discrete(labels=c('pre', 'post')) +
  theme(legend.title=element_blank(), legend.position = "bottom")
```

To get one summary estimate across time points we use the `fit_event_jack_sum()`
function because the effects are dynamic across adoption cohorts:

```{r}
s8_bm2 <- fit_event_jack_sum(outcome_var = "outcome", 
                        date_var = "time_as_date", 
                        unit_var = "state",
                        policy_var = "time_first_trt_date", 
                        data = s8, 
                        max_time_to = 10e7)

s8_bm2$estimate
```

This gives the same estimate as produced by the Group-Time ATT estimator when 
specifying `type = "dynamic"` in the `aggte()` function, and also equals
`r emo::ji("orange_book")` `r colorize("Causal Effect B", orange_hex)`.

If instead you want to estimate the overarching ATT using the same approach as
used when `type = "group"`, you can use the `fit_event_jack_sum_hte()` function:

```{r}
s8_bm3 <- fit_event_jack_sum_hte(outcome_var = "outcome", 
                        date_var = "time_as_date", 
                        unit_var = "state",
                        policy_var = "time_first_trt_date", 
                        data = s8, 
                        max_time_to = 10e7)

s8_bm3$estimate
```

This is equal to `r emo::ji("blue_book")` `r colorize("Causal Effect A", blue_hex)`.

Finally if you want to estimate the overarching ATT using the same approach as used when type = "simple" you can use the `fit_event_jack_sum_C()` function:

```{r}
s8_bm4 <- fit_event_jack_sum_C(outcome_var = "outcome", 
                        date_var = "time_as_date", 
                        unit_var = "state",
                        policy_var = "time_first_trt_date", 
                        data = s8, 
                        max_time_to = 10e7)

s8_bm4$estimate
```

This is equal to `r emo::ji("green_book")` `r colorize("Causal Effect C", green_hex)`.


## TWFE with `time_since_policy` specification

But what if we run the TWFE model with the `time_since_change` indicators? Here,
I run the regression and `filter()` out the policy estimates for easy viewing 
since the regression table is so large:

```{r}
s8_mod2 <- lm(outcome ~ time_since_policy + state + factor(time), 
             data = s8)
tidy(s8_mod2) %>% filter(str_detect(term, "time_since")) %>% 
  mutate(time = as.numeric(gsub("time_since_policy", "", term))) %>% 
  arrange(time) 
```

The effect estimates on the policy indicators do not equal an average of the ATTs
from the two states for each time period. For this example, this specification 
gives estimates that are systematically lower than the parameters we aim to 
estimate and to the estimates produced by the Group-Time estimator and the 
Target Trial estimator. 

## Summary

When the treatment effect is staggered, dynamic, and heterogeneous, 
the TWFE regression specification can produced biased results, as will the 
specification using a categorical variable for time since treatment. In this 
case, use one of the newer estimators. 

# Scenario 9 (24 states, staggered timing, dynamic and hetergenous treatment effects)

So far, we have considered simpler examples where the outcomes didn't incorporate 
noise. This was helpful for getting started, but doesn't reflect the imprecision
in estimates based on real-world data. Furthermore, we couldn't estimate 
standard errors because there was not error in the estimation. 

This scenario is more realistic. It increases the number of treated and control 
units, as is common in analyses across several geographic areas like states. We
also added variability to the outcome, with different amounts of variability by 
state to reflect units containing varying sample sizes.

```{r}
s9_start <- read_xlsx(here("data", "scenarios.xlsx"), sheet = "scen9", 
                col_types = c("text", "numeric", "text", "numeric", "text", "numeric"))

# we hid some code here from displaying in the html version of this file where
# we build up this scenario and add noise. Please view the Rmd document to see
# these lines of code!
```

```{r, echo=F}
set.seed(112358)
#expand on the s9 dataset to include many states 
state_base1 <- s9_start %>% filter(state == 1)
length <- dim(state_base1)[1]
state10 <- state_base1 %>% mutate(outcome = outcome  + rnorm(length, 0, 2),
                                  state = 10)
state11 <- state_base1 %>% mutate(outcome = outcome  + rnorm(length, 0, 8),
                                  state = 11)
state12 <- state_base1 %>% mutate(outcome = outcome  + rnorm(length, 0, 2.3),
                                  state = 12)
state13 <- state_base1 %>% mutate(outcome = outcome  + rnorm(length, 0, 3),
                                  state = 13)
state14 <- state_base1 %>% mutate(outcome = outcome  + rnorm(length, 0, 1),
                                  state = 14)
state15 <- state_base1 %>% mutate(outcome = outcome  + rnorm(length, 0, 5),
                                  state = 15)
states_1015 <- bind_rows(state10, state11, state12, state13, state14, state15)

state_base2 <- s9_start %>% filter(state == 2)
length <- dim(state_base2)[1]
state20 <- state_base2 %>% mutate(outcome = outcome  + rnorm(length, 0, 2),
                                  state = 20)
state21 <- state_base2 %>% mutate(outcome = outcome  + rnorm(length, 0, 8),
                                  state = 21)
state22 <- state_base2 %>% mutate(outcome = outcome  + rnorm(length, 0, 2.3),
                                  state = 22)
state23 <- state_base2 %>% mutate(outcome = outcome  + rnorm(length, 0, 3),
                                  state = 23)
state24 <- state_base2 %>% mutate(outcome = outcome  + rnorm(length, 0, 1),
                                  state = 24)
state25 <- state_base2 %>% mutate(outcome = outcome  + rnorm(length, 0, 5),
                                  state = 25)
states_2025 <- bind_rows(state20, state21, state22, state23, state24, state25)

state_base3 <- s9_start %>% filter(state == 3)
length <- dim(state_base3)[1]
state30 <- state_base3 %>% mutate(outcome = outcome  + rnorm(length, 0, 2),
                                  state = 30)
state31 <- state_base3 %>% mutate(outcome = outcome  + rnorm(length, 0, 8),
                                  state = 31)
state32 <- state_base3 %>% mutate(outcome = outcome  + rnorm(length, 0, 2.3),
                                  state = 32)
state33 <- state_base3 %>% mutate(outcome = outcome  + rnorm(length, 0, 3),
                                  state = 33)
state34 <- state_base3 %>% mutate(outcome = outcome  + rnorm(length, 0, 1),
                                  state = 34)
state35 <- state_base3 %>% mutate(outcome = outcome  + rnorm(length, 0, 5),
                                  state = 35)
states_3035 <- bind_rows(state30, state31, state32, state33, state34, state35)

state_base4 <- s9_start %>% filter(state == 4)
length <- dim(state_base4)[1]
state40 <- state_base4 %>% mutate(outcome = outcome  + rnorm(length, 0, 2),
                                  state = 40)
state41 <- state_base4 %>% mutate(outcome = outcome  + rnorm(length, 0, 8),
                                  state = 41)
state42 <- state_base4 %>% mutate(outcome = outcome  + rnorm(length, 0, 2.3),
                                  state = 42)
state43 <- state_base4 %>% mutate(outcome = outcome  + rnorm(length, 0, 3),
                                  state = 43)
state44 <- state_base4 %>% mutate(outcome = outcome  + rnorm(length, 0, 1),
                                  state = 44)
state45 <- state_base4 %>% mutate(outcome = outcome  + rnorm(length, 0, 5),
                                  state = 45)

states_4045 <- bind_rows(state40, state41, state42, state43, state44, state45)

all_states <- bind_rows(states_1015, states_2025, states_3035, states_4045)
```

## Visualization of Scenario 8

```{r, echo = F}
all_states %<>% mutate(ever_trt = case_when(state > 25 ~ "treated", 
                                            state <= 25 ~ "untreated")
                       )

ggplot(all_states, aes(x = time, y = outcome)) + 
  geom_line(aes(col = factor(time_first_treat), group = state)) +
  geom_point(aes(fill = factor(time_first_treat), pch = ever_trt)) +
  labs(title = "Scenario 8 (Numerous states, staggered, dynamic, and heterogeneous)") +
  geom_vline(aes(xintercept = 14.5), lty = 2, col = treated5_green) + 
  geom_vline(aes(xintercept = 21.5), lty = 2, col = treated12_red) +
  scale_color_manual(values = c(control1_blue, treated5_green, treated12_red)) +
  scale_fill_manual(values = c(control1_blue, treated5_green, treated12_red)) +
  scale_shape_manual(values = c(23, 21)) + 
  theme_bw()
```

**Visualization of all comparisons made by TWFE regression**

```{r, echo = F, fig.height = 8, fig.width = 10}
s9_comp1 <- ggplot(all_states %>% filter(state <= 35), aes(x = time, y = outcome)) +   
  geom_line(aes(col = factor(ever_trt), group = state)) + 
  geom_point(aes(fill = factor(ever_trt), pch = ever_trt, group = state)) + labs(title = "A) Contrast 1 (Treated vs. never-treated)") +
  geom_vline(aes(xintercept = 14.5), lty = 2, col = treated5_green) +
  scale_x_continuous(limits = c(1, 30))  + 
  scale_color_manual(values = c(treated5_green, control1_blue)) +
  scale_fill_manual(values = c(treated5_green, control1_blue)) +
  scale_shape_manual(values = c(21, 23)) + 
  theme_bw() 

s9_comp2 <- ggplot(all_states %>% filter(state <= 25 | state >= 40), aes(x = time, y = outcome)) +   
  geom_line(aes(col = factor(ever_trt), group = state)) + 
  geom_point(aes(fill = factor(ever_trt), pch = ever_trt, group = state)) + labs(title = "B) Contrast 2 (Treated vs. never-treated)") +
  geom_vline(aes(xintercept = 21.5), lty = 2, col = treated12_red) +
  scale_x_continuous(limits = c(1, 30))  + 
  scale_color_manual(values = c(treated12_red, control1_blue)) +
  scale_fill_manual(values = c(treated12_red, control1_blue)) +
  scale_shape_manual(values = c(21, 23)) + 
  theme_bw() 

s9_comp4 <- ggplot(all_states %>% filter(state >= 30, time >= 15), aes(x = time, y = outcome)) +
  geom_line(aes(col = factor(time_first_treat), group = state)) + 
  geom_point(aes(fill = factor(time_first_treat), group = state, pch = ever_trt), show.legend = F) + 
  labs(title = "C) Contrast 4 (Later vs. earlier-treated)") +
  geom_vline(aes(xintercept = 21.5), lty = 2, col = treated12_red) +
  scale_x_continuous(limits = c(1, 30))  + 
  scale_color_manual(values = c(treated5_green, treated12_red)) +
  scale_fill_manual(values = c(treated5_green, treated12_red)) +
  scale_shape_manual(values = c(23)) + 
  theme_bw() 

s9_comp3 <- ggplot(all_states %>% filter(state >= 30, time < 22), aes(x = time, y = outcome)) +   
  geom_line(aes(col = factor(time_first_treat), group = state)) + 
  geom_point(aes(fill = factor(time_first_treat), group = state, pch = ever_trt), show.legend = F) +
  labs(title = "D) Contrast 3 (Earlier vs. later-treated)") +
  geom_vline(aes(xintercept = 14.5), lty = 2, col = treated5_green) +
  scale_x_continuous(limits = c(1, 30))  + 
  scale_color_manual(values = c(treated5_green, treated12_red)) +
  scale_fill_manual(values = c(treated5_green, treated12_red)) +
  scale_shape_manual(values = c(23)) + 
  theme_bw() 

s9_comp1 + s9_comp2 + s9_comp3 + s9_comp4 + plot_layout(guides = "collect")
```

We start by running the linear model as we have done previously:

```{r}
s9_mod <- lm(outcome ~ policy + factor(state) + factor(time), 
             data = all_states)
tidy(s9_mod)
```

Up until now, we haven't worried about the estimation of the 95% confidence 
interval because our previous datasets didn't contain any noise. In practice,
we want to estimate confidence intervals and to do that correctly, we need to 
account for the clustering on data over time within state. To do that we use the 
`vcovHC` function from the `sandwich` package. 

```{r}
#install.packages("sandwich")
library(sandwich)
m2_var <- vcovHC(s9_mod)
```

We can then pull out the variance from the `policy1` term from the 
variance-covariance matrix and use it to compute Wald type confidence intervals:

```{r}
est = summary(s9_mod)$coefficients["policy1", "Estimate"] 
lb = summary(s9_mod)$coefficients["policy1", "Estimate"] - 1.96*sqrt(m2_var["policy1","policy1"]) 
ub = summary(s9_mod)$coefficients["policy1", "Estimate"] + 1.96*sqrt(m2_var["policy1","policy1"])
```

The estimated effect is `r round(est, 1)` with a 95% CI from `r sprintf("%.1f", round(lb, 1))`
to `r round(ub, 1)`.

## Goodman Bacon Decomposition

We can use the Goodman Bacon decomposition to examine the contrasts contributing to the 
TWFE estimate. 

The DID contrasts for the four comparisons are:

i) Treated at time 15 vs. never-treated: 18 
ii) Treated at time 22 vs. never-treated: 5
iii) Treated at time 22 vs. post-treatment time for states treated at time 5: -11
iv) Treated at time 5 vs. pre-treatment time for states treated at time 22: 9

We can compare this to the output from the Goodman Bacon decomposition:

```{r}
all_states %<>% mutate(policy_n = as.numeric(policy))

s9_bacon <- bacon(outcome ~ policy_n,
      data = all_states,
      id_var = "state",
      time_var = "time")

s9_bacon
```

We can see that the estimates displayed in the second table are not too far off
from the DID contrasts listed above. For this scenario, 84% of the weight is on 
the treated vs. untreated and about 10% of the weight is on the earlier vs. the 
later treated, with only 6% of the weight on the forbidden contrast. In the 
next section we will see how these weights change if pre-treatment time is 
shortened.

## Group-Time ATT Estimator

Compare to Callaway and Sant'Anna's approach. We will start be specifying 
`type="simple" in the aggte() function`:

```{r}
s9_cs <- att_gt(yname = "outcome", 
             tname = "time", 
             idname = "state", 
             gname = "time_first_treat", 
             data = all_states, 
             control_group = "nevertreated",
             anticipation = 0)

s9_cs_ag <- aggte(s9_cs, type="simple")
summary(s9_cs_ag)

lb = s9_cs_ag$overall.att - 1.96*s9_cs_ag$overall.se 
ub = s9_cs_ag$overall.att + 1.96*s9_cs_ag$overall.se
round(c(s9_cs_ag$overall.att, lb, ub), 2)
```

The Group-Time estimate is `r s9_cs_ag$overall.att %>% round(2)` with 95% CI `r lb %>% round(2)` 
to `r ub %>% round(2)`.

The simple ATT is a weighted average (based on the amount of time in the 
post-treatment period) of the estimated effects for the treated groups calculated 
like this: 

```{r}
(19.09088*(16/25)) + (2.324934*(9/25))
```

To figure out what the group specific estimates are we use `type = group`:

```{r}
s9_cs_ag2 <- aggte(s9_cs, type = "group")
summary(s9_cs_ag2)
```

Here the overall ATT is a simple average of the group-specific ATTs (`r round((s9_cs_ag2$att.egt[1] + s9_cs_ag2$att.egt[2])/2, 4)`).

Finally, we can look at these effect estimates separately for each time since 
the intervention began and graph them: 

```{r}
s9_cs_ag3 <- aggte(s9_cs, type="dynamic")
summary(s9_cs_ag3)
```

```{r, fig.width=10}
ggdid(s9_cs_ag3)
```

Now that we have confidence intervals, we can assess the parallel trends 
assumption by investigating if the pre-treatment confidence intervals overlap the null and are
randomly distributed around the zero line. This is true in our example, so we
wouldn't be concerned about violating the parallel trends assumption with these
data. 

## Cohort ATT Estimator

Now we can also calculate effects using the Cohort ATT estimator. We couldn't 
run this estimator for the other scenarios because the function throws an error 
if it is unable to estimate standard errors. To use the `staggered_sa` function, 
we need to add a new variable where the `time_first_treat` variable is set to 
`Inf` for all states that were never-treated:

```{r}
table(all_states$time_first_treat, useNA = "always")
all_states$time_first_treat2 <- all_states$time_first_treat
all_states$time_first_treat2[all_states$time_first_treat == 0] <- Inf

#check that the recoding is as planned:
table(all_states$time_first_treat, all_states$time_first_treat2, useNA = "always")
```

For this function, we need to specify the data frame in the `df` argument, the
clustering unit in the `i` argument, the time unit in the `t` argument. Here we 
use the newly-defined `time_first_treat2` as the grouping variable `g`. We start
by setting `estimand = "simple"`:

```{r SA-simple}
s9_sa <- staggered_sa(df = all_states,
                      i = "state",
                      t = "time",
                      g = "time_first_treat2",
                      y = "outcome", 
                      estimand = "simple")
```

The estimate of the treatment effect is `r s9_sa$estimate %>% round(2)`, which
is equivalent to the effect estimate from the Group-Time ATT estimator when 
`type = "simple"`. We can calculate its confidence interval using either of these:

```{r}
#95% CI
round(c(s9_sa$estimate, s9_sa$estimate - 1.96*s9_sa$se, s9_sa$estimate + 1.96*s9_sa$se), 2)
round(c(s9_sa$estimate, s9_sa$estimate - 1.96*s9_sa$se_neyman, s9_sa$estimate + 1.96*s9_sa$se_neyman), 2)
```
To calculate an average weights by group size (or cohort size using the 
terminology employed in this function), we set `estimand = "cohort"`:

```{r SA-cohort}
s9_sa_group <- staggered_sa(df = all_states,
                      i = "state",
                      t = "time",
                      g = "time_first_treat2",
                      y = "outcome", 
                      estimand = "cohort")

s9_sa_group$estimate

#95% CI
round(c(s9_sa_group$estimate, 
        s9_sa_group$estimate - 1.96*s9_sa_group$se, 
        s9_sa_group$estimate + 1.96*s9_sa_group$se), 2)
round(c(s9_sa_group$estimate, 
        s9_sa_group$estimate - 1.96*s9_sa_group$se_neyman, 
        s9_sa_group$estimate + 1.96*s9_sa_group$se_neyman), 2)
```

Here, the Cohort ATT effect estimate is equivalent to the Group-Time estimate where `type = "group"`.

Finally, we can also use the Cohort ATT function to calculate dynamic effect
estimates by setting `estimand = "eventstudy"`. This function also requires we 
specify which event times we would like estimates for. To produce estimates we
can compare with the Group Time ATT effects, we specify `eventTime = c(-20:15)`, 
which says to begin looking 20 time points before the policy change up until 15
time points after the policy change.

```{r}
times <- c(-20:15)

s9_sa_dynamic <- staggered_sa(df = all_states,
                      i = "state",
                      t = "time",
                      g = "time_first_treat2",
                      y = "outcome", 
                      estimand = "eventstudy",
                      eventTime = times)

# gather the estimates and CI information into a data frame for plotting
sa_dynamic_estimates <- tibble(
  `Event Time` = times,
  `Estimate` = s9_sa_dynamic$estimate, 
  `Std. Error` = s9_sa_dynamic$se,
  `95% lower bound` = s9_sa_dynamic$estimate - 1.96*s9_sa_dynamic$se,
  `95% upper bound` = s9_sa_dynamic$estimate + 1.96*s9_sa_dynamic$se,
  `Std. Error (Neyman)` = s9_sa_dynamic$se_neyman,
  `95% lower bound (Neyman)` = s9_sa_dynamic$estimate - 1.96*s9_sa_dynamic$se_neyman,
  `95% upper bound (Neyman)` = s9_sa_dynamic$estimate + 1.96*s9_sa_dynamic$se_neyman)
sa_dynamic_estimates
```

We can then create a plot similar to the one produced by the `ggdid()` command:

```{r}
ggplot(sa_dynamic_estimates, aes(x = `Event Time`, y = Estimate)) + 
  geom_hline(yintercept = 0) + 
  geom_linerange(aes(xmin = `Event Time`, 
                     ymin = `95% lower bound (Neyman)`, 
                     ymax = `95% upper bound (Neyman)`,
                     col = `Event Time` >= 0)) + 
  geom_point(aes(col = `Event Time` >= 0)) +
  theme_bw() +
  scale_color_discrete(labels=c('pre', 'post')) +
  theme(legend.title=element_blank(), legend.position = "bottom")
```

Overall, the Group-Time estimates and Cohort ATT estimates are quite
close and have overlapping confidence intervals. Favorably, the summary 
estimates are both higher than the TWFE estimate because they do not use 
information based on the forbidden contrast.

## Target Trial Estimator

We also consider the Target trial estimator. This function relies on the date 
variable being a date object rather than a
numeric index. Without loss of generality, we add dates to this dataset picking
Jan 1, 2015 as the start date by way of exposition and incrementing time by 
one-month intervals:

```{r}
all_states$time2 <- as.Date("2015-01-01") #date 0
all_states$period1 <- paste(all_states$time, " month")
all_states$time3 <- all_states$time2 %m+% period(all_states$period1) #new time variable

all_states %<>% select(-period1, -time2)
```

To use this estimator, the `time_first_treat` variable needs to be set to 
missing for the untreated states for the function to run:

```{r}
all_states %<>% 
  mutate(time_first_treat3 = case_when(time_first_treat2 == 15 ~ as.Date("2016-04-01"),
                                       time_first_treat2 == 22 ~ as.Date("2016-11-01"),
                                       is.infinite(time_first_treat2) ~ NA_Date_))

#check the coding
#table(all_states2$time_first_treat2, all_states2$time_first_treat3, useNA = "ifany")
```

Then we compute the estimates and plot them. The results are very similar to the
Group-Time ATT and Cohort ATT estimates plot, showing no discernible trends in 
the pre-exposure period, and an increasing effect of treatment in the 
post-exposure period.

```{r}
s9_bm <- fit_event_jack(outcome_var = "outcome", 
                        date_var = "time3", 
                        unit_var = "state",
                        policy_var = "time_first_treat3", 
                        data = all_states, 
                        max_time_to = 10e7)

s9_bm_ave <- s9_bm %>% filter(cohort == "average")

s9_bm_ave %<>% mutate(lb = estimate - 1.96*se,
                      ub = estimate + 1.96*se)

ggplot(s9_bm_ave, aes(x = event_time, y = estimate)) + 
  geom_hline(yintercept = 0, lty = 2) +
  geom_point(aes(col = event_time >= 0)) + 
  geom_linerange(aes(ymin = lb, ymax = ub, col = event_time >= 0)) + 
  labs(y = "Estimate", x = "Event time") + 
  theme_bw() + 
  scale_color_discrete(labels=c('pre', 'post')) +
  theme(legend.title=element_blank(), legend.position = "bottom")
```

We then use the `fit_event_jack_sum` set of functions to calculate the ATT using 
three different methods:

```{r}
s9_bm_sum <- fit_event_jack_sum(outcome_var = "outcome", 
                        date_var = "time3", 
                        unit_var = "state",
                        policy_var = "time_first_treat3", 
                        data = all_states, 
                        max_time_to = 10e7)

s9_bm_sum %<>% mutate(lb = estimate - 1.96*se,
                      ub = estimate + 1.96*se)

s9_bm_sum
```

```{r}
s9_bm_sum_hte <- fit_event_jack_sum_hte(outcome_var = "outcome", 
                        date_var = "time3", 
                        unit_var = "state",
                        policy_var = "time_first_treat3", 
                        data = all_states, 
                        max_time_to = 10e7)

s9_bm_sum_hte %<>% mutate(lb = estimate - 1.96*se,
                      ub = estimate + 1.96*se)

s9_bm_sum_hte
```
```{r}
s9_bm_sum_simple <- fit_event_jack_sum_C(outcome_var = "outcome", 
                        date_var = "time3", 
                        unit_var = "state",
                        policy_var = "time_first_treat3", 
                        data = all_states, 
                        max_time_to = 10e7)

s9_bm_sum_simple %<>% mutate(lb = estimate - 1.96*se,
                      ub = estimate + 1.96*se)

s9_bm_sum_simple
```

# Scenario 10 (same as previous but with less pre-exposure time)

In this scenario, we use the same data from Scenario 9, except we limit the 
pre-intervention point to 5 time units, rather than the 15 
in Scenario 9. The amount of pre-intervention time should not affect the size of 
the effect estimate because the size of the change from the previous scenario is
the same. The goal of this scenario is to see how the different estimators are 
affected by this change in the amount of pre-intervention time.

We start by limiting the time frame to begin at time t=10 or larger:

```{r}
all_states2 <- all_states %>% filter(time >= 10)
```

## Comparison of TWFE Estimates 

And then we re-run the model: 

```{r}
s10_mod <- lm(outcome ~ policy + factor(state) + factor(time), 
             data = all_states2)
tidy(s10_mod)
```

Again, we use the `vcovHC` function to estimate the SE and obtain the 
95% confidence interval for the policy coefficient:

```{r}
m2_var <- vcovHC(s10_mod)
est2 = summary(s10_mod)$coefficients["policy1", "Estimate"] 
lb2 = summary(s10_mod)$coefficients["policy1", "Estimate"] - 1.96*sqrt(m2_var["policy1","policy1"]) 
ub2 = summary(s10_mod)$coefficients["policy1", "Estimate"] + 1.96*sqrt(m2_var["policy1","policy1"])
```

The estimated effect is `r round(est2, 1)` with a 95% CI from `r sprintf("%.1f", round(lb2, 1))`
to `r round(ub2, 1)`. Let's compare this with the estimate from Scenario 9:

|           | Estimate (95% CI) | 
|----------:|:------------------|
|Scenario 9 | `r paste0(round(est, 1), " (", sprintf("%.1f", round(lb, 1)), ",", round(ub, 1), ")")`  | 
|Scenario 10 | `r paste0(round(est2, 1), " (", sprintf("%.1f", round(lb2, 1)), ",", round(ub2, 1), ")")` |

The estimate for Scenario 10 is much lower than that for Scenario
9. 

## Comparison of Goodman Bacon decomposition weights

Let's see how the weights from the Bacon decomposition for Scenario 10 compare
to Scenario 9. 

Scenario 10 weights:

```{r}
all_states2 %<>% mutate(policy_n = as.numeric(policy))

s10_bacon <- bacon(outcome ~ policy_n,
      data = all_states2,
      id_var = "state",
      time_var = "time")

s10_bacon
```

Scenario 9 weights:

```{r}
s9_bacon

```

Comparing the weights:

```{r, echo=F}
s9_weights <- s9_bacon %>% select(weight) %>% rename(`Scenario 9 weight` = weight)  
compare_bacon <- s10_bacon %>% rename(`Scenario 10 weight` = weight) 
comparison <- bind_cols(s9_weights, compare_bacon) %>% relocate(`Scenario 9 weight`, .before = `Scenario 10 weight`)
comparison %>% mutate(`Weight difference` = `Scenario 10 weight` - `Scenario 9 weight`) %>% 
  mutate_if(is.numeric, ~round(., 2)) %>% relocate(type, .after = last_col())
```

More weight is put on the states treated at time=22 in Scenario
10 vs. 9 and less weight on the states treated at time=15. This is because the 
TWFE estimator is a weighted combination of contrasts, where the weights are partially 
determined by how close the contrast is to the middle of the panel.
More weight is put on the estimates for groups with changes closer to the middle of
the panel. For Scenario 9, the states with treatment changes at time 15 are exactly
in the middle of the panel (which had 30 time units), but for Scenario 10, with 
a shortened pre-treatment period, less weight is put on this group as they are
further away from the middle of the panel and more weight is put on the group 
that introduced treatment at time point 22 because this becomes closer to the middle.

This weighting does not likely correspond to any weighting 
that the researcher would choose. Concerning!

## Comparison of Group-Time Estimates

Let's see how the other estimators are affected by this change:

```{r}
s10_cs <- att_gt(yname = "outcome", 
             tname = "time", 
             idname = "state", 
             gname = "time_first_treat", 
             data = all_states2, 
             control_group = "notyettreated",
             anticipation = 0)

s10_cs_ag <- aggte(s10_cs, type="simple")
summary(s10_cs_ag)
```

The Callaway Sant'Anna estimate of the ATT is the same as for Scenario 9 (with
a slightly lower standard error).

## Comparison of Cohort ATT estimates

What about the Cohort ATT estimate? 

```{r}
s10_sa <- staggered_sa(df = all_states2,
                      i = "state",
                      t = "time",
                      g = "time_first_treat2",
                      y = "outcome", 
                      estimand = "simple")

s10_sa$estimate
round(c(s9_sa$estimate, s9_sa$estimate - 1.96*s9_sa$se, s9_sa$estimate + 1.96*s9_sa$se), 2)
round(c(s9_sa$estimate, s9_sa$estimate - 1.96*s9_sa$se_neyman, s9_sa$estimate + 1.96*s9_sa$se_neyman), 2)
```

Like the Group-Time ATT estimate, the Cohort ATT estimate stays exactly the same.

## Comparison of the Target trial estimates

Lastly, what happens to the Target Trial estimates? We compare them below:

```{r}
s9_bm_hte <- fit_event_jack_sum_hte(outcome_var = "outcome", 
                        date_var = "time3", 
                        unit_var = "state",
                        policy_var = "time_first_treat3", 
                        data = all_states, 
                        max_time_to = 10e7)

s9_bm_hte %<>% mutate(lb = estimate - 1.96*se,
                      ub = estimate + 1.96*se)

s9_bm_hte

s10_bm_hte <- fit_event_jack_sum_hte(outcome_var = "outcome", 
                        date_var = "time3", 
                        unit_var = "state",
                        policy_var = "time_first_treat3", 
                        data = all_states2, 
                        max_time_to = 10e7)

s10_bm_hte %<>% mutate(lb = estimate - 1.96*se,
                      ub = estimate + 1.96*se)

s10_bm_hte
```

The Target Trial estimates stay exactly the same as well.

## Summary

The TWFE estimate is affected by the length of the panel. It places
more weight on contrasts that are closer to the middle of the panel. The 
newer estimators do not have this issue. 